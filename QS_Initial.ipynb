{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2eF090CA03X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import firebase_admin\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import ast\n",
    "import fire\n",
    "import pymongo\n",
    "import pickle\n",
    "import itertools\n",
    "from firebase_admin import credentials, firestore, storage\n",
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "from adaptive_learning.scheduler import DashScheduler\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "cred = credentials.Certificate(\"machine-learning-database.json\")\n",
    "app = firebase_admin.initialize_app(cred,{'storageBucket': 'machine-learning-databas-9d23e.appspot.com'})\n",
    "firestore_client = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "class QuestionSelect:\n",
    "    def __init__(self, course_name, dash_path, concept_path):\n",
    "        self.course_name = course_name\n",
    "        self.dash_params = self.load_pickle(dash_path)\n",
    "        self.concept_file = self.load_pickle(concept_path)\n",
    "    \n",
    "    def load_pickle(self, pickle_file_path):\n",
    "        with open(pickle_file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        return data\n",
    "    \n",
    "    def GetQuestions(self):\n",
    "        questions_dict = {}\n",
    "        course_list = []\n",
    "        course = self.course_name\n",
    "\n",
    "        ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\")\n",
    "        for lec in ref.get():\n",
    "            ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\").document(lec.id).collection(\"Moments\")\n",
    "            for moment in ref.get():\n",
    "                ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\").document(lec.id).collection(\"Moments\").document(moment.id).collection(\"Multiple Choice Questions\")\n",
    "                for q in ref.get():\n",
    "                    questions_dict[q.id] = q.to_dict()\n",
    "                    course_list.append(course)\n",
    "\n",
    "        question_statements = []\n",
    "        A_list = []\n",
    "        B_list = []\n",
    "        C_list = []\n",
    "        D_list = []\n",
    "        week_list = []\n",
    "        correct_list = []\n",
    "        moment_list = []\n",
    "        question_topics = []\n",
    "        for q in questions_dict.values():\n",
    "            question_statements.append(q[\"Question\"])\n",
    "            A_list.append(q[\"A\"])\n",
    "            B_list.append(q[\"B\"])\n",
    "            C_list.append(q[\"C\"])\n",
    "            D_list.append(q[\"D\"])\n",
    "            correct_list.append(q[\"Correct answer\"])\n",
    "            moment_list.append(q[\"Moment\"])\n",
    "            question_topics.append(q[\"Topics\"])\n",
    "\n",
    "        quest_df = pd.DataFrame({\n",
    "        \"Question ID\": questions_dict.keys(),\n",
    "        \"Question\": question_statements,\n",
    "        \"A\": A_list,\n",
    "        \"B\": B_list,\n",
    "        \"C\": C_list,\n",
    "        \"D\": D_list,\n",
    "        \"Correct\": correct_list,\n",
    "        \"Moment\" : moment_list,\n",
    "        \"Topics\" : question_topics})\n",
    "\n",
    "        quest_df['Selected'] = False\n",
    "        quest_df['Topics'] = quest_df['Topics'].apply(lambda topics: [topic.lower() for topic in topics])\n",
    "\n",
    "        return quest_df\n",
    "\n",
    "    def explode_list(self, df, column_to_explode):\n",
    "        df = df.reset_index(drop=True)\n",
    "        s = df[column_to_explode]\n",
    "        i = np.arange(len(s)).repeat(s.str.len())\n",
    "        return df.iloc[i].assign(**{column_to_explode: np.concatenate(s)})\n",
    "\n",
    "\n",
    "    def get_dash_memory(self, dash_params,concepts, progress):\n",
    "        if progress is None: # if progress is not provided...\n",
    "            # then, provide a default value for progress\n",
    "            progress = {'progress': [(5, 0, '08/08/2023'), (16, 1, '08/09/2023'), (5, 0, '08/10/2023'), (9, 0, '08/11/2023'), (4, 1, '08/12/2023'),\n",
    "                             (0, 1, '08/13/2023'), (10, 1, '08/14/2023'), (11, 1, '08/15/2023'), (19, 0, '08/16/2023'), (10, 1, '08/17/2023'),\n",
    "                             (18, 0, '08/18/2023'), (3, 1, '08/19/2023'), (1, 1, '08/20/2023'), (5, 1, '08/21/2023'), (5, 0, '08/22/2023'),\n",
    "                             (0, 1, '08/23/2023'), (17, 1, '08/24/2023'), (5, 0, '08/25/2023'), (2, 0, '08/26/2023'), (16, 1, '08/27/2023'),\n",
    "                             (1, 0, '08/28/2023'), (12, 0, '08/29/2023'), (20, 1, '08/30/2023'), (7, 0, '08/31/2023'), (14, 1, '09/01/2023'),\n",
    "                             (20, 1, '09/02/2023'), (8, 1, '09/03/2023'), (8, 1, '09/04/2023'), (4, 0, '09/05/2023'), (7, 1, '09/06/2023')]\n",
    "                        }\n",
    "        scheduler = DashScheduler(concepts, dash_params)\n",
    "        return scheduler.get_memory(progress['progress'])    \n",
    "\n",
    "    def GetFrequency(self, df, student_uniqname):\n",
    "        rec_prob={}\n",
    "        \n",
    "        #Creating concept name to concept id dictionary\n",
    "        id2concept = {k: c for k, c in enumerate(self.concept_file.nodes())}    \n",
    "        id2concept = {k: v.strip() for k, v in id2concept.items()}\n",
    "        concept2id = {v.strip(): k for k, v in id2concept.items()}\n",
    "        \n",
    "        output = None\n",
    "        if df is None or df.empty:\n",
    "            # no df provided, so get_dash_memory uses its default progress\n",
    "            output = self.get_dash_memory(self.dash_params,self.concept_file,None)\n",
    "            \n",
    "        else:\n",
    "            # Only process df if it's not None,\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "            df['correct/incorrect'] = (df['response'] == df['correct_answer']).astype(int)\n",
    "            df = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "\n",
    "            #Format student history in suitable format for dash api\n",
    "            df_formatted = self.explode_list(df, 'topics_covered')\n",
    "            df_formatted.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "            df_formatted.reset_index(drop=True, inplace=True)\n",
    "            df_formatted['concept'] = df_formatted['concept'].map(concept2id)\n",
    "            df_formatted = df_formatted[df_formatted['concept'].apply(lambda x: str(x).isdigit())]\n",
    "            df_formatted['concept'] = df_formatted['concept'].astype(int)\n",
    "            tuple_list = [tuple(x) for x in df_formatted.values]\n",
    "            student_hist = {'progress': tuple_list}\n",
    "\n",
    "            # Get recall probabilities from the api\n",
    "            output = self.get_dash_memory(self.dash_params,self.concept_file,student_hist)\n",
    "            \n",
    "            \n",
    "#         #student history data from the database (code for connecting an online database must be added here)\n",
    "#         df = df[df['student_id']==student_uniqname]          #filter by student\n",
    "#         df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "#         df['correct/incorrect'] = (df['response'] == df['correct_answer']).astype(int)\n",
    "#         df = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "        \n",
    "#         #Format student history in suitable format for dash api\n",
    "#         df_formatted = self.explode_list(df, 'topics_covered')\n",
    "#         df_formatted.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "#         df_formatted.reset_index(drop=True, inplace=True)\n",
    "#         df_formatted['concept'] = df_formatted['concept'].map(concept2id)\n",
    "#         df_formatted = df_formatted[df_formatted['concept'].apply(lambda x: str(x).isdigit())]\n",
    "#         df_formatted['concept'] = df_formatted['concept'].astype(int)\n",
    "#         tuple_list = [tuple(x) for x in df_formatted.values]\n",
    "#         student_hist = {'progress': tuple_list}\n",
    "        \n",
    "#         #Get recall probabilities from the api\n",
    "#         output = self.get_dash_memory(self.dash_params, self.concept_file, student_hist['progress'])\n",
    "\n",
    "\n",
    "        for i in output:\n",
    "            k = int(i[1])\n",
    "            v = float(i[0])\n",
    "            rec_prob[k] = v\n",
    "            \n",
    "        #Formatting the recall probabilites to frequency in the correct format\n",
    "        recall_prob_dict = {id2concept.get(k, k): v for k, v in rec_prob.items()}\n",
    "        recall_prob_dict = {k.strip(): v for k, v in recall_prob_dict.items()}\n",
    "        recall_prob_dict = dict(sorted(recall_prob_dict.items(), key=lambda item: item[1]))\n",
    "        first_25_dict = dict(itertools.islice(recall_prob_dict.items(), 25))\n",
    "        frequencies = {k: round(1/(v**0.5)) for k,v in first_25_dict.items()}\n",
    "        return frequencies\n",
    "\n",
    "    def QuestionSelect(self, frequencies, quest_df, max_questions):\n",
    "        # Start with all topic frequencies being the target ones\n",
    "        unsatisfied_freqs = {k: v for k, v in frequencies.items() if v != 0}\n",
    "        selected_questions = []\n",
    "\n",
    "        # Greedy selection of questions\n",
    "        while unsatisfied_freqs and len(selected_questions) < max_questions:\n",
    "\n",
    "            # Calculate the score of each question by conditionally filtering unselected questions, \n",
    "            # and only if they cover a topic with unsatisfied frequency remaining\n",
    "            question_scores = {q: sum(unsatisfied_freqs[topic] for topic in topics \n",
    "                                      if topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0)\n",
    "                               for q, topics in quest_df[quest_df.Selected == False].set_index('Question').Topics.items() \n",
    "                               if any(topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0 for topic in topics)}\n",
    "\n",
    "            # If no question can satisfy the remaining unsatisfied frequencies, then break the loop\n",
    "            if not question_scores:\n",
    "                print(\"No more questions can satisfy the remaining topic frequencies.\")\n",
    "                break\n",
    "\n",
    "            # Select the question with the highest score\n",
    "            selected_q = max(question_scores, key=question_scores.get)\n",
    "            selected_questions.append(selected_q)\n",
    "\n",
    "            # Update the 'Selected' flag for the chosen question\n",
    "            quest_df.loc[quest_df.Question == selected_q, 'Selected'] = True\n",
    "\n",
    "            # Update the unsatisfied frequencies\n",
    "            for topic_list in quest_df.set_index('Question').loc[selected_q].Topics:  # Assume here each topic_list is a list\n",
    "                for topic in topic_list:  # Iterate over the items in each topic_list\n",
    "                    if topic in unsatisfied_freqs:\n",
    "                        unsatisfied_freqs[topic] -= 1\n",
    "                        if unsatisfied_freqs[topic] == 0:\n",
    "                            unsatisfied_freqs.pop(topic)\n",
    "\n",
    "        selected_questions_df = pd.DataFrame(selected_questions, columns=['Question'])\n",
    "        final_df = selected_questions_df.merge(quest_df, on='Question', how='left')\n",
    "        return final_df\n",
    "\n",
    "# class QuestionSelect:\n",
    "    \n",
    "#     with open('dash_params.pk', 'rb') as file:\n",
    "#         dash = pickle.load(file)\n",
    "    \n",
    "#     with open('SIADS_542_dep.pk', 'rb') as file:\n",
    "#         concept_file = pickle.load(file)\n",
    "        \n",
    "#     def GetQuestions(course_name):\n",
    "#         questions_dict = {}\n",
    "#         course_list = []\n",
    "#         course = course_name\n",
    "\n",
    "#         ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\")\n",
    "#         for lec in ref.get():\n",
    "#             ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\").document(lec.id).collection(\"Moments\")\n",
    "#             for moment in ref.get():\n",
    "#                 ref = firestore_client.collection(\"Courses\").document(course).collection(\"Lectures\").document(lec.id).collection(\"Moments\").document(moment.id).collection(\"Multiple Choice Questions\")\n",
    "#                 for q in ref.get():\n",
    "#                     questions_dict[q.id] = q.to_dict()\n",
    "#                     course_list.append(course)\n",
    "\n",
    "#         question_statements = []\n",
    "#         A_list = []\n",
    "#         B_list = []\n",
    "#         C_list = []\n",
    "#         D_list = []\n",
    "#         week_list = []\n",
    "#         correct_list = []\n",
    "#         moment_list = []\n",
    "#         question_topics = []\n",
    "#         for q in questions_dict.values():\n",
    "#             question_statements.append(q[\"Question\"])\n",
    "#             A_list.append(q[\"A\"])\n",
    "#             B_list.append(q[\"B\"])\n",
    "#             C_list.append(q[\"C\"])\n",
    "#             D_list.append(q[\"D\"])\n",
    "#             correct_list.append(q[\"Correct answer\"])\n",
    "#             moment_list.append(q[\"Moment\"])\n",
    "#             question_topics.append(q[\"Topics\"])\n",
    "\n",
    "#         quest_df = pd.DataFrame({\n",
    "#         \"Question ID\": questions_dict.keys(),\n",
    "#         \"Question\": question_statements,\n",
    "#         \"A\": A_list,\n",
    "#         \"B\": B_list,\n",
    "#         \"C\": C_list,\n",
    "#         \"D\": D_list,\n",
    "#         \"Correct\": correct_list,\n",
    "#         \"Moment\" : moment_list,\n",
    "#         \"Topics\" : question_topics})\n",
    "\n",
    "#         quest_df['Selected'] = False\n",
    "#         quest_df['Topics'] = quest_df['Topics'].apply(lambda topics: [topic.lower() for topic in topics])\n",
    "\n",
    "#         return quest_df\n",
    "\n",
    "#     def explode_list(df, column_to_explode, fill_values):\n",
    "#         df = df.reset_index(drop=True)\n",
    "#         s = df[column_to_explode]\n",
    "#         i = np.arange(len(s)).repeat(s.str.len())\n",
    "#         return df.iloc[i].assign(**{column_to_explode: np.concatenate(s)})\n",
    "\n",
    "\n",
    "#     def get_dash_memory(dash_params,concepts, progress):\n",
    "#         scheduler = DashScheduler(concepts, dash_params)\n",
    "#         return scheduler.get_memory(progress)    \n",
    "\n",
    "#     def GetFrequency(df, student_uniqname, concept_dict):\n",
    "#         rec_prob={}\n",
    "        \n",
    "#         #Creating concept name to concept id dictionary\n",
    "#         id2concept = {k: c for k, c in enumerate(concept_file.nodes())}\n",
    "#         concept2id = {v.strip(): k for k, v in id2concept.items()}\n",
    "        \n",
    "#         #student history data from the database (code for connecting an online database must be added here)\n",
    "#         df = df[df['student_id']==student_uniqname]\n",
    "#         df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "#         df['correct/incorrect'] = (df['response'] == df['correct_answer']).astype(int)\n",
    "#         df = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "        \n",
    "#         #Format student history in suitable format for dash api\n",
    "#         df_formatted = explode_list(df, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "#         df_formatted.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "#         df_formatted.reset_index(drop=True, inplace=True)\n",
    "#         df_formatted['concept'] = df_formatted['concept'].map(concept2id)\n",
    "#         df_formatted = df_formatted[df_formatted['concept'].apply(lambda x: str(x).isdigit())]\n",
    "#         df_formatted['concept'] = df_formatted['concept'].astype(int)\n",
    "#         tuple_list = [tuple(x) for x in df_formatted.values]\n",
    "#         student_hist = {'progress': tuple_list}\n",
    "        \n",
    "#         #Get recall probabilities from the api\n",
    "#         output = get_dash_memory(dash, concept_file, student_hist['progress'])\n",
    "#         for i in output:\n",
    "#             k = int(i[1])\n",
    "#             v = float(i[0])\n",
    "#             rec_prob[k] = v\n",
    "            \n",
    "#         #Formatting the recall probabiites to frequency in the correct format\n",
    "#         recall_prob_dict = {id2concept.get(k, k): v for k, v in rec_prob.items()}\n",
    "#         recall_prob_dict = {k.strip(): v for k, v in recall_prob_dict.items()}\n",
    "#         recall_prob_dict = dict(sorted(recall_prob_dict.items(), key=lambda item: item[1]))\n",
    "#         first_25_dict = dict(itertools.islice(recall_prob_dict.items(), 25))\n",
    "#         frequencies = {k: round(1/(v**0.5)) for k,v in recall_prob_dict.items()}\n",
    "#         return frequencies\n",
    "\n",
    "#     def QuestionSelect(frequencies, quest_df):\n",
    "#         # Start with all topic frequencies being the target ones\n",
    "#         unsatisfied_freqs = {k: v for k, v in frequencies.items() if v != 0}\n",
    "#         selected_questions = []\n",
    "\n",
    "#         # Greedy selection of questions\n",
    "#         while unsatisfied_freqs:\n",
    "\n",
    "#             # Calculate the score of each question by conditionally filtering unselected questions, and only if they cover a topic with unsatisfied frequency remaining\n",
    "#             question_scores = {q: sum(unsatisfied_freqs[topic] for topic in topics if topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0)\n",
    "#                               for q, topics in quest_df[quest_df.Selected == False].set_index('Question').Topics.items() if any(topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0 for topic in topics)}\n",
    "\n",
    "#             # If no question can satisfy the remaining unsatisfied frequencies, then break the loop\n",
    "#             if not question_scores:\n",
    "#                 print(\"No more questions can satisfy the remaining topic frequencies.\")\n",
    "#                 break\n",
    "\n",
    "#             # Select the question with the highest score\n",
    "#             selected_q = max(question_scores, key=question_scores.get)\n",
    "#             selected_questions.append(selected_q)\n",
    "\n",
    "#             # Update the 'Selected' flag for the chosen question\n",
    "#             quest_df.loc[quest_df.Question == selected_q, 'Selected'] = True\n",
    "\n",
    "#             # Update the unsatisfied frequencies\n",
    "#             for topic_list in quest_df.set_index('Question').loc[selected_q].Topics:  # Assume here each topic_list is a list\n",
    "#                 for topic in topic_list:  # Iterate over the items in each topic_list\n",
    "#                     if topic in unsatisfied_freqs:\n",
    "#                         unsatisfied_freqs[topic] -= 1\n",
    "#                         if unsatisfied_freqs[topic] == 0:\n",
    "#                             unsatisfied_freqs.pop(topic)\n",
    "\n",
    "#         selected_questions_df = pd.DataFrame(selected_questions, columns=['Question'])\n",
    "#         final_df = selected_questions_df.merge(quest_df, on='Question', how='left')\n",
    "#         return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_path = 'dash_params.pk'\n",
    "concept_path = 'SIADS_542_dep.pk'\n",
    "selector = QuestionSelect('SIADS 542',concept_path, dash_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Moment</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3KVQWnBwdP6v583JjDLr</td>\n",
       "      <td>What is the practical application of the machi...</td>\n",
       "      <td>Automated quality control in food companies</td>\n",
       "      <td>Screening for rotten oranges during processing</td>\n",
       "      <td>Estimating the mass of different fruits</td>\n",
       "      <td>Both A and B</td>\n",
       "      <td>D</td>\n",
       "      <td>Moment 1</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5RDWHCXtn9kGlet8yOcU</td>\n",
       "      <td>What types of fruit were included in the origi...</td>\n",
       "      <td>Oranges, lemons, and apples</td>\n",
       "      <td>Oranges and lemons</td>\n",
       "      <td>Apples and oranges</td>\n",
       "      <td>Lemons and apples</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 1</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5bXvM0sWuWJkMePjS6fk</td>\n",
       "      <td>Where can the dataset be found?</td>\n",
       "      <td>In the folder of materials downloaded for the ...</td>\n",
       "      <td>In the University of Edinburgh's database</td>\n",
       "      <td>In a nearby store</td>\n",
       "      <td>In a fruit shipping company's database</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 1</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7uG85sDYzmhOBpTCS0Bu</td>\n",
       "      <td>What additional features were added to the ori...</td>\n",
       "      <td>Color score</td>\n",
       "      <td>Fruit type</td>\n",
       "      <td>Fruit size</td>\n",
       "      <td>Fruit weight</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 1</td>\n",
       "      <td>[feature engineering, supervised learning, cla...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9HduaghaahWg3Ap4sLL7</td>\n",
       "      <td>Who originally created the dataset used in the...</td>\n",
       "      <td>Dr. Iain Murray</td>\n",
       "      <td>The author of the text</td>\n",
       "      <td>A food company</td>\n",
       "      <td>A fruit shipping company</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 1</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>ao8nhfDoW7dBCKT6CnaH</td>\n",
       "      <td>What does the y-axis represent in the scatter ...</td>\n",
       "      <td>The regression target</td>\n",
       "      <td>The future value</td>\n",
       "      <td>The data set samples</td>\n",
       "      <td>The informative input variable</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 2</td>\n",
       "      <td>[regression, supervised learning, linear regre...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>gLR5Buv5fv1VyDgLvlDb</td>\n",
       "      <td>What is the purpose of low dimensional example...</td>\n",
       "      <td>To make the model more complex</td>\n",
       "      <td>To understand how the model's complexity chang...</td>\n",
       "      <td>To reduce the model's complexity</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>B</td>\n",
       "      <td>Moment 2</td>\n",
       "      <td>[learning curve, supervised learning, unsuperv...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>mogJEvUhtAZSqfa1xdDP</td>\n",
       "      <td>What does the x-axis represent in the scatter ...</td>\n",
       "      <td>The regression target</td>\n",
       "      <td>The future value</td>\n",
       "      <td>The data set samples</td>\n",
       "      <td>The informative input variable</td>\n",
       "      <td>B</td>\n",
       "      <td>Moment 2</td>\n",
       "      <td>[regression, classification, feature engineeri...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>tBmxLQbGIITOpX0GcFLy</td>\n",
       "      <td>What is the purpose of randomly flipping the c...</td>\n",
       "      <td>To make the classifier more challenging</td>\n",
       "      <td>To make the data set more complex</td>\n",
       "      <td>To reduce the complexity of the classifier</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>A</td>\n",
       "      <td>Moment 2</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>twFOMaWcyqHfOIV2eFZb</td>\n",
       "      <td>What function is used to create the regression...</td>\n",
       "      <td>make_classification</td>\n",
       "      <td>make_regression</td>\n",
       "      <td>make_data</td>\n",
       "      <td>make_plot</td>\n",
       "      <td>B</td>\n",
       "      <td>Moment 2</td>\n",
       "      <td>[regression, supervised learning, feature engi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Question ID                                           Question  \\\n",
       "0     3KVQWnBwdP6v583JjDLr  What is the practical application of the machi...   \n",
       "1     5RDWHCXtn9kGlet8yOcU  What types of fruit were included in the origi...   \n",
       "2     5bXvM0sWuWJkMePjS6fk                    Where can the dataset be found?   \n",
       "3     7uG85sDYzmhOBpTCS0Bu  What additional features were added to the ori...   \n",
       "4     9HduaghaahWg3Ap4sLL7  Who originally created the dataset used in the...   \n",
       "...                    ...                                                ...   \n",
       "1105  ao8nhfDoW7dBCKT6CnaH  What does the y-axis represent in the scatter ...   \n",
       "1106  gLR5Buv5fv1VyDgLvlDb  What is the purpose of low dimensional example...   \n",
       "1107  mogJEvUhtAZSqfa1xdDP  What does the x-axis represent in the scatter ...   \n",
       "1108  tBmxLQbGIITOpX0GcFLy  What is the purpose of randomly flipping the c...   \n",
       "1109  twFOMaWcyqHfOIV2eFZb  What function is used to create the regression...   \n",
       "\n",
       "                                                      A  \\\n",
       "0           Automated quality control in food companies   \n",
       "1                           Oranges, lemons, and apples   \n",
       "2     In the folder of materials downloaded for the ...   \n",
       "3                                           Color score   \n",
       "4                                       Dr. Iain Murray   \n",
       "...                                                 ...   \n",
       "1105                              The regression target   \n",
       "1106                     To make the model more complex   \n",
       "1107                              The regression target   \n",
       "1108            To make the classifier more challenging   \n",
       "1109                                make_classification   \n",
       "\n",
       "                                                      B  \\\n",
       "0        Screening for rotten oranges during processing   \n",
       "1                                    Oranges and lemons   \n",
       "2             In the University of Edinburgh's database   \n",
       "3                                            Fruit type   \n",
       "4                                The author of the text   \n",
       "...                                                 ...   \n",
       "1105                                   The future value   \n",
       "1106  To understand how the model's complexity chang...   \n",
       "1107                                   The future value   \n",
       "1108                  To make the data set more complex   \n",
       "1109                                    make_regression   \n",
       "\n",
       "                                               C  \\\n",
       "0        Estimating the mass of different fruits   \n",
       "1                             Apples and oranges   \n",
       "2                              In a nearby store   \n",
       "3                                     Fruit size   \n",
       "4                                 A food company   \n",
       "...                                          ...   \n",
       "1105                        The data set samples   \n",
       "1106            To reduce the model's complexity   \n",
       "1107                        The data set samples   \n",
       "1108  To reduce the complexity of the classifier   \n",
       "1109                                   make_data   \n",
       "\n",
       "                                           D Correct    Moment  \\\n",
       "0                               Both A and B       D  Moment 1   \n",
       "1                          Lemons and apples       A  Moment 1   \n",
       "2     In a fruit shipping company's database       A  Moment 1   \n",
       "3                               Fruit weight       A  Moment 1   \n",
       "4                   A fruit shipping company       A  Moment 1   \n",
       "...                                      ...     ...       ...   \n",
       "1105          The informative input variable       A  Moment 2   \n",
       "1106                       None of the above       B  Moment 2   \n",
       "1107          The informative input variable       B  Moment 2   \n",
       "1108                       None of the above       A  Moment 2   \n",
       "1109                               make_plot       B  Moment 2   \n",
       "\n",
       "                                                 Topics  Selected  \n",
       "0     [supervised learning, classification, feature ...     False  \n",
       "1     [supervised learning, classification, feature ...     False  \n",
       "2     [supervised learning, classification, feature ...     False  \n",
       "3     [feature engineering, supervised learning, cla...     False  \n",
       "4     [supervised learning, classification, feature ...     False  \n",
       "...                                                 ...       ...  \n",
       "1105  [regression, supervised learning, linear regre...     False  \n",
       "1106  [learning curve, supervised learning, unsuperv...     False  \n",
       "1107  [regression, classification, feature engineeri...     False  \n",
       "1108  [supervised learning, classification, feature ...     False  \n",
       "1109  [regression, supervised learning, feature engi...     False  \n",
       "\n",
       "[1110 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest_df = selector.GetQuestions()\n",
    "quest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = quest_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_list = [[\"Supervised learning\", \"Classification\", \"Feature engineering\", \"Data Cleaning\", \"Decision trees\"],\n",
    "# [\"Supervised learning\", \"Feature engineering\", \"Data Cleaning\", \"Classification\", \"Regression\"],\n",
    "# [\"Supervised learning\", \"Classification\", \"Feature engineering\", \"Decision trees\", \"k-NN\"],\n",
    "# [\"Supervised learning\", \"Classification\", \"Feature engineering\", \"Bias variance tradeoff\", \"Train test split\"],\n",
    "# [\"Data Cleaning\", \"Feature engineering\", \"Anomaly detection\", \"Supervised learning\", \"Unsupervised learning\"],\n",
    "# [\"Feature engineering\", \"Supervised learning\", \"Classification\", \"Data Cleaning\", \"Clustering\"],\n",
    "# [\"Data Cleaning\", \"Feature engineering\", \"Supervised learning\", \"Classification\", \"Regression\"],\n",
    "# [\"k-NN\", \"Supervised learning\", \"Classification\", \"Feature engineering\", \"Majority vote\"],\n",
    "# [\"k-NN\", \"Classification\", \"Feature engineering\", \"Supervised learning\", \"Decision trees\"],\n",
    "# [\"k-NN\", \"Supervised learning\", \"Classification\", \"Feature engineering\", \"Decision trees\"],\n",
    "# [\"k-NN\", \"Supervised learning\", \"Classification\", \"Bias variance tradeoff\", \"Feature engineering\"],\n",
    "# [\"Supervised learning\", \"Classification\", \"Regression\", \"Feature engineering\", \"Artificial neural networks\"],\n",
    "# [\"Supervised learning\", \"Crowdsourcing\", \"Human-in-the-loop\", \"Active learning\", \"Learning curve\"],\n",
    "# [\"Unsupervised learning\", \"Clustering\", \"Anomaly detection\", \"Feature learning\", \"Online learning\"],\n",
    "# [\"Supervised learning\", \"Unsupervised learning\", \"Classification\", \"Feature engineering\", \"Evaluation method\"],\n",
    "# [\"k-NN\", \"Classification\", \"Overfitting\", \"Supervised learning\", \"Bias variance tradeoff\"],\n",
    "# [\"Regression\", \"Linear regression\", \"Bias variance tradeoff\", \"Supervised learning\", \"Overfitting\"],\n",
    "# [\"Supervised learning\", \"Classification\", \"Regression\", \"Overfitting\", \"Generalization\"],\n",
    "# [\"Classification\", \"Clustering\", \"Regression\", \"Feature engineering\", \"Supervised learning\"],\n",
    "# [\"Linear regression\", \"Classification\", \"Supervised learning\", \"Feature engineering\", \"Scatter plot\"],\n",
    "# [\"Supervised learning\", \"Feature engineering\", \"dimension reduction\", \"Artificial neural networks\", \"Bias variance tradeoff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_df = quest_df.copy(True)\n",
    "# subset_df['Topics_sorted'] = subset_df['Topics'].apply(lambda x: sorted(x))\n",
    "# topic_list_sorted = [sorted(sublist) for sublist in topic_list]\n",
    "\n",
    "# # Then we convert the sorted topics back into a single string\n",
    "# subset_df['Topics_str'] = subset_df['Topics_sorted'].astype(str)\n",
    "# topic_list_strs = [str(sublist) for sublist in topic_list_sorted]\n",
    "\n",
    "# # Then we filter the DataFrame to only include rows with a 'Topics_str' in our topic_list_strs\n",
    "# subset_df = subset_df[subset_df['Topics_str'].isin(topic_list_strs)]\n",
    "\n",
    "# # And we remove the columns we created for this operation \n",
    "# subset_df = subset_df.drop(['Topics_sorted', 'Topics_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_df['Selected'] = False\n",
    "# subset_df['Topics'] = subset_df['Topics'].apply(lambda topics: [topic.lower() for topic in topics])\n",
    "# subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quest_df.Topics.explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dash_memory(current_app, concepts, progress):\n",
    "#     scheduler = DashScheduler(concepts, current_app.dash_params)\n",
    "#     return scheduler.get_memory(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# url = 'https://comphcithree.eecs.umich.edu:8100/concepts/siads542' #your url here\n",
    "\n",
    "# # Sends a HTTP request to the specified URL and save \n",
    "# # the response from server in a response object called r\n",
    "# r = requests.get(url)\n",
    "\n",
    "# # Create a dictionary from JSON file\n",
    "# concept_dict = r.json()\n",
    "\n",
    "# # print the dictionary\n",
    "# concept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SSPsiAh5V1B",
    "outputId": "1e6901e3-eaba-4316-d93a-717e7f71aabc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_concept_tree(current_app, course_name):\n",
    "#     concepts = current_app.concepts[course_name]\n",
    "#     concept_dict = {\"concept2id\":\n",
    "#                     {concept: idx for concept, idx in enumerate(concepts.nodes())},\n",
    "#                     \"edges\": list(concepts.edges())}\n",
    "#     return concept_dict\n",
    "\n",
    "# get_concept_tree(app,\"SIADS 542\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random datetime between `start` and `end`.\"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = random.randrange(int_delta)\n",
    "    return start + timedelta(seconds=random_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2023, 8, 29)\n",
    "end_date = datetime(2023, 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'vcLXNsUiJSycyILeGxjl',\n",
       "  'question_id': 'vcLXNsUiJSycyILeGxjl',\n",
       "  'question': 'What is the strategy of a dummy regressor?',\n",
       "  'response': 'A',\n",
       "  'correct_answer': 'D',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 9, 8, 8, 44, 20),\n",
       "  'topics_covered': ['regression',\n",
       "   'supervised learning',\n",
       "   'linear regression',\n",
       "   'bias variance tradeoff',\n",
       "   'statistical learning']},\n",
       " {'_id': 'yhX8I5hMcHhbRRRgy6v7',\n",
       "  'question_id': 'yhX8I5hMcHhbRRRgy6v7',\n",
       "  'question': 'What is the purpose of training and testing on the same data set?',\n",
       "  'response': 'A',\n",
       "  'correct_answer': 'B',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 9, 9, 9, 42, 54),\n",
       "  'topics_covered': ['supervised learning',\n",
       "   'overfitting',\n",
       "   'feature engineering',\n",
       "   'model selection',\n",
       "   'evaluation metrics',\n",
       "   'training and testing',\n",
       "   'cross-validation',\n",
       "   'grid search',\n",
       "   'accuracy']},\n",
       " {'_id': 'S1gJrP9CdXFRekbMZGcx',\n",
       "  'question_id': 'S1gJrP9CdXFRekbMZGcx',\n",
       "  'question': 'What is the difference between ridge regression and lasso regression?',\n",
       "  'response': 'D',\n",
       "  'correct_answer': 'B',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 9, 21, 15, 40, 28),\n",
       "  'topics_covered': ['linear regression',\n",
       "   'regression',\n",
       "   'supervised learning',\n",
       "   'bias variance tradeoff',\n",
       "   'statistical learning']},\n",
       " {'_id': '2pxk5NtR5sOV9uTsHqL4',\n",
       "  'question_id': '2pxk5NtR5sOV9uTsHqL4',\n",
       "  'question': 'What is the difference between K nearest neighbors regression and least squares linear regression?',\n",
       "  'response': 'B',\n",
       "  'correct_answer': 'C',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 10, 12, 21, 20, 39),\n",
       "  'topics_covered': ['k-nn',\n",
       "   'linear regression',\n",
       "   'supervised learning',\n",
       "   'regression',\n",
       "   'bias variance tradeoff']},\n",
       " {'_id': '4EDUpqKPGThAVcJ10Uvc',\n",
       "  'question_id': '4EDUpqKPGThAVcJ10Uvc',\n",
       "  'question': 'What does a beta larger than one in the F-score imply?',\n",
       "  'response': 'D',\n",
       "  'correct_answer': 'B',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 9, 11, 15, 38, 33),\n",
       "  'topics_covered': ['supervised learning',\n",
       "   'classification',\n",
       "   'bias variance tradeoff',\n",
       "   'statistical learning',\n",
       "   'feature engineering']},\n",
       " {'_id': 'Mfxl89wLhpbtbDXprjLs',\n",
       "  'question_id': 'Mfxl89wLhpbtbDXprjLs',\n",
       "  'question': 'Does Mean Squared Error distinguish between over and underestimates?',\n",
       "  'response': 'A',\n",
       "  'correct_answer': 'B',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 10, 5, 6, 16, 45),\n",
       "  'topics_covered': ['regression',\n",
       "   'linear regression',\n",
       "   'supervised learning',\n",
       "   'bias variance tradeoff',\n",
       "   'statistical learning']},\n",
       " {'_id': 'qgACHvxcUdxV1FGHDVRD',\n",
       "  'question_id': 'qgACHvxcUdxV1FGHDVRD',\n",
       "  'question': \"What does the string 'precision_micro' represent in the context of evaluation metrics?\",\n",
       "  'response': 'C',\n",
       "  'correct_answer': 'A',\n",
       "  'student_id': 'ABCDE',\n",
       "  'timestamp': datetime.datetime(2023, 9, 4, 1, 8, 41),\n",
       "  'topics_covered': ['supervised learning',\n",
       "   'classification',\n",
       "   'feature engineering',\n",
       "   'support vector machine (svm)',\n",
       "   'precision recall trade-off']}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_row(row):\n",
    "    return {\n",
    "        \"_id\": row[\"Question ID\"],  # Assuming Question ID is unique and can be used as _id\n",
    "        \"question_id\": row[\"Question ID\"],\n",
    "        \"question\": row[\"Question\"],\n",
    "        \"response\": random.choice([\"A\", \"B\", \"C\", \"D\"]),\n",
    "        \"correct_answer\": row[\"Correct\"],\n",
    "        \"student_id\": 'ABCDE',\n",
    "        \"timestamp\": random_date(start_date, end_date),  # Random timestamp\n",
    "        \"topics_covered\": row[\"Topics\"],  # Assuming topics are separated by semicolons\n",
    "        # Add or modify fields as necessary to match your MongoDB schema\n",
    "    }\n",
    "\n",
    "transformed_data = [transform_row(row) for index, row in sample_df.iterrows()]\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "UJDFzbe421ge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>student_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>topics_covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcLXNsUiJSycyILeGxjl</td>\n",
       "      <td>vcLXNsUiJSycyILeGxjl</td>\n",
       "      <td>What is the strategy of a dummy regressor?</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-08 08:44:20</td>\n",
       "      <td>[regression, supervised learning, linear regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yhX8I5hMcHhbRRRgy6v7</td>\n",
       "      <td>yhX8I5hMcHhbRRRgy6v7</td>\n",
       "      <td>What is the purpose of training and testing on...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-09 09:42:54</td>\n",
       "      <td>[supervised learning, overfitting, feature eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1gJrP9CdXFRekbMZGcx</td>\n",
       "      <td>S1gJrP9CdXFRekbMZGcx</td>\n",
       "      <td>What is the difference between ridge regressio...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-21 15:40:28</td>\n",
       "      <td>[linear regression, regression, supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2pxk5NtR5sOV9uTsHqL4</td>\n",
       "      <td>2pxk5NtR5sOV9uTsHqL4</td>\n",
       "      <td>What is the difference between K nearest neigh...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-10-12 21:20:39</td>\n",
       "      <td>[k-nn, linear regression, supervised learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4EDUpqKPGThAVcJ10Uvc</td>\n",
       "      <td>4EDUpqKPGThAVcJ10Uvc</td>\n",
       "      <td>What does a beta larger than one in the F-scor...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-11 15:38:33</td>\n",
       "      <td>[supervised learning, classification, bias var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mfxl89wLhpbtbDXprjLs</td>\n",
       "      <td>Mfxl89wLhpbtbDXprjLs</td>\n",
       "      <td>Does Mean Squared Error distinguish between ov...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-10-05 06:16:45</td>\n",
       "      <td>[regression, linear regression, supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qgACHvxcUdxV1FGHDVRD</td>\n",
       "      <td>qgACHvxcUdxV1FGHDVRD</td>\n",
       "      <td>What does the string 'precision_micro' represe...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-04 01:08:41</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id           question_id  \\\n",
       "0  vcLXNsUiJSycyILeGxjl  vcLXNsUiJSycyILeGxjl   \n",
       "1  yhX8I5hMcHhbRRRgy6v7  yhX8I5hMcHhbRRRgy6v7   \n",
       "2  S1gJrP9CdXFRekbMZGcx  S1gJrP9CdXFRekbMZGcx   \n",
       "3  2pxk5NtR5sOV9uTsHqL4  2pxk5NtR5sOV9uTsHqL4   \n",
       "4  4EDUpqKPGThAVcJ10Uvc  4EDUpqKPGThAVcJ10Uvc   \n",
       "5  Mfxl89wLhpbtbDXprjLs  Mfxl89wLhpbtbDXprjLs   \n",
       "6  qgACHvxcUdxV1FGHDVRD  qgACHvxcUdxV1FGHDVRD   \n",
       "\n",
       "                                            question response correct_answer  \\\n",
       "0         What is the strategy of a dummy regressor?        A              D   \n",
       "1  What is the purpose of training and testing on...        A              B   \n",
       "2  What is the difference between ridge regressio...        D              B   \n",
       "3  What is the difference between K nearest neigh...        B              C   \n",
       "4  What does a beta larger than one in the F-scor...        D              B   \n",
       "5  Does Mean Squared Error distinguish between ov...        A              B   \n",
       "6  What does the string 'precision_micro' represe...        C              A   \n",
       "\n",
       "  student_id           timestamp  \\\n",
       "0      ABCDE 2023-09-08 08:44:20   \n",
       "1      ABCDE 2023-09-09 09:42:54   \n",
       "2      ABCDE 2023-09-21 15:40:28   \n",
       "3      ABCDE 2023-10-12 21:20:39   \n",
       "4      ABCDE 2023-09-11 15:38:33   \n",
       "5      ABCDE 2023-10-05 06:16:45   \n",
       "6      ABCDE 2023-09-04 01:08:41   \n",
       "\n",
       "                                      topics_covered  \n",
       "0  [regression, supervised learning, linear regre...  \n",
       "1  [supervised learning, overfitting, feature eng...  \n",
       "2  [linear regression, regression, supervised lea...  \n",
       "3  [k-nn, linear regression, supervised learning,...  \n",
       "4  [supervised learning, classification, bias var...  \n",
       "5  [regression, linear regression, supervised lea...  \n",
       "6  [supervised learning, classification, feature ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "uri = 'mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1'\n",
    "client = pymongo.MongoClient(uri)\n",
    "db = client[\"student_histDB\"]\n",
    "\n",
    "collection = db[\"questions\"]\n",
    "documents = collection.find()\n",
    "# for doc in documents:\n",
    "#     print(doc)\n",
    "doc_count = collection.count_documents({})    \n",
    "print(doc_count)\n",
    "\n",
    "df = pd.DataFrame(list(documents))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f893981c760>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete existing questions (be cautious with this approach)\n",
    "collection.delete_many({})\n",
    "\n",
    "# Insert new questions\n",
    "collection.insert_many(transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>topics_covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6585277dcb09d40dbd65ef40</td>\n",
       "      <td>3DROdxl5vsYX75KG8Nh1</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.195</td>\n",
       "      <td>What is an example of multi-label classification?</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>[supervised learning, classification, regressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6585277dcb09d40dbd65ef41</td>\n",
       "      <td>88VMmjviJzZ9Ns6RluNm</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.237</td>\n",
       "      <td>What is the target value in a classification p...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>[supervised learning, classification, regressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6585277dcb09d40dbd65ef42</td>\n",
       "      <td>XpUuyTKzrepqaDyAy8MO</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.238</td>\n",
       "      <td>What does the term 'false negative' mean?</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>[classification, supervised learning, bias var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6585277dcb09d40dbd65ef43</td>\n",
       "      <td>aBbyvV7gbu1l3yLOOCSb</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.238</td>\n",
       "      <td>What does the term 'true positive' mean?</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>[classification, supervised learning, artifici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6585277dcb09d40dbd65ef44</td>\n",
       "      <td>rR48xocrkcgI7IoLedH3</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.239</td>\n",
       "      <td>What is the first parameter of the cross_val_s...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>[supervised learning, online learning, batch l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6585277dcb09d40dbd65ef45</td>\n",
       "      <td>FNZ11XAkzDkE9YM53RZS</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.239</td>\n",
       "      <td>What is the goal of doing a real-world deploym...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[supervised learning, data cleaning, feature e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6585277dcb09d40dbd65ef46</td>\n",
       "      <td>w4F7oVjQADat4DCvxuqL</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.239</td>\n",
       "      <td>What is the problem in classification?</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[classification, supervised learning, k-nn, ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6585277dcb09d40dbd65ef47</td>\n",
       "      <td>NPglbiW5dlDwY9AdQ4n2</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.240</td>\n",
       "      <td>What is an example of a binary classification ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>[supervised learning, classification, regressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6585277dcb09d40dbd65ef48</td>\n",
       "      <td>5cdduX5WQqaDMTLdlIe9</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.240</td>\n",
       "      <td>What does a higher value of C in logistic regr...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>[logistic regression, supervised learning, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6585277dcb09d40dbd65ef49</td>\n",
       "      <td>KGm8Zqtw04Y6rdnGwAc6</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-12-22 01:06:53.241</td>\n",
       "      <td>What is the probability estimate y hat used for?</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>[logistic regression, supervised learning, cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id           question_id student_id  \\\n",
       "0  6585277dcb09d40dbd65ef40  3DROdxl5vsYX75KG8Nh1      ABCDE   \n",
       "1  6585277dcb09d40dbd65ef41  88VMmjviJzZ9Ns6RluNm      ABCDE   \n",
       "2  6585277dcb09d40dbd65ef42  XpUuyTKzrepqaDyAy8MO      ABCDE   \n",
       "3  6585277dcb09d40dbd65ef43  aBbyvV7gbu1l3yLOOCSb      ABCDE   \n",
       "4  6585277dcb09d40dbd65ef44  rR48xocrkcgI7IoLedH3      ABCDE   \n",
       "5  6585277dcb09d40dbd65ef45  FNZ11XAkzDkE9YM53RZS      ABCDE   \n",
       "6  6585277dcb09d40dbd65ef46  w4F7oVjQADat4DCvxuqL      ABCDE   \n",
       "7  6585277dcb09d40dbd65ef47  NPglbiW5dlDwY9AdQ4n2      ABCDE   \n",
       "8  6585277dcb09d40dbd65ef48  5cdduX5WQqaDMTLdlIe9      ABCDE   \n",
       "9  6585277dcb09d40dbd65ef49  KGm8Zqtw04Y6rdnGwAc6      ABCDE   \n",
       "\n",
       "                timestamp                                           question  \\\n",
       "0 2023-12-22 01:06:53.195  What is an example of multi-label classification?   \n",
       "1 2023-12-22 01:06:53.237  What is the target value in a classification p...   \n",
       "2 2023-12-22 01:06:53.238          What does the term 'false negative' mean?   \n",
       "3 2023-12-22 01:06:53.238           What does the term 'true positive' mean?   \n",
       "4 2023-12-22 01:06:53.239  What is the first parameter of the cross_val_s...   \n",
       "5 2023-12-22 01:06:53.239  What is the goal of doing a real-world deploym...   \n",
       "6 2023-12-22 01:06:53.239             What is the problem in classification?   \n",
       "7 2023-12-22 01:06:53.240  What is an example of a binary classification ...   \n",
       "8 2023-12-22 01:06:53.240  What does a higher value of C in logistic regr...   \n",
       "9 2023-12-22 01:06:53.241   What is the probability estimate y hat used for?   \n",
       "\n",
       "  response correct_answer                                     topics_covered  \n",
       "0        A              C  [supervised learning, classification, regressi...  \n",
       "1        C              B  [supervised learning, classification, regressi...  \n",
       "2        B              B  [classification, supervised learning, bias var...  \n",
       "3        C              C  [classification, supervised learning, artifici...  \n",
       "4        D              B  [supervised learning, online learning, batch l...  \n",
       "5        A              A  [supervised learning, data cleaning, feature e...  \n",
       "6        A              A  [classification, supervised learning, k-nn, ov...  \n",
       "7        B              B  [supervised learning, classification, regressi...  \n",
       "8        A              B  [logistic regression, supervised learning, cla...  \n",
       "9        D              A  [logistic regression, supervised learning, cla...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db[\"studenthist\"]\n",
    "documents = collection.find()\n",
    "# for doc in documents:\n",
    "#     print(doc)\n",
    "doc_count = collection.count_documents({})    \n",
    "print(doc_count)\n",
    "\n",
    "df = pd.DataFrame(list(documents))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>student_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>topics_covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcLXNsUiJSycyILeGxjl</td>\n",
       "      <td>vcLXNsUiJSycyILeGxjl</td>\n",
       "      <td>What is the strategy of a dummy regressor?</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-08 08:44:20</td>\n",
       "      <td>[regression, supervised learning, linear regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yhX8I5hMcHhbRRRgy6v7</td>\n",
       "      <td>yhX8I5hMcHhbRRRgy6v7</td>\n",
       "      <td>What is the purpose of training and testing on...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-09 09:42:54</td>\n",
       "      <td>[supervised learning, overfitting, feature eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1gJrP9CdXFRekbMZGcx</td>\n",
       "      <td>S1gJrP9CdXFRekbMZGcx</td>\n",
       "      <td>What is the difference between ridge regressio...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-21 15:40:28</td>\n",
       "      <td>[linear regression, regression, supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2pxk5NtR5sOV9uTsHqL4</td>\n",
       "      <td>2pxk5NtR5sOV9uTsHqL4</td>\n",
       "      <td>What is the difference between K nearest neigh...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-10-12 21:20:39</td>\n",
       "      <td>[k-nn, linear regression, supervised learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4EDUpqKPGThAVcJ10Uvc</td>\n",
       "      <td>4EDUpqKPGThAVcJ10Uvc</td>\n",
       "      <td>What does a beta larger than one in the F-scor...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-11 15:38:33</td>\n",
       "      <td>[supervised learning, classification, bias var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mfxl89wLhpbtbDXprjLs</td>\n",
       "      <td>Mfxl89wLhpbtbDXprjLs</td>\n",
       "      <td>Does Mean Squared Error distinguish between ov...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-10-05 06:16:45</td>\n",
       "      <td>[regression, linear regression, supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qgACHvxcUdxV1FGHDVRD</td>\n",
       "      <td>qgACHvxcUdxV1FGHDVRD</td>\n",
       "      <td>What does the string 'precision_micro' represe...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>ABCDE</td>\n",
       "      <td>2023-09-04 01:08:41</td>\n",
       "      <td>[supervised learning, classification, feature ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id           question_id  \\\n",
       "0  vcLXNsUiJSycyILeGxjl  vcLXNsUiJSycyILeGxjl   \n",
       "1  yhX8I5hMcHhbRRRgy6v7  yhX8I5hMcHhbRRRgy6v7   \n",
       "2  S1gJrP9CdXFRekbMZGcx  S1gJrP9CdXFRekbMZGcx   \n",
       "3  2pxk5NtR5sOV9uTsHqL4  2pxk5NtR5sOV9uTsHqL4   \n",
       "4  4EDUpqKPGThAVcJ10Uvc  4EDUpqKPGThAVcJ10Uvc   \n",
       "5  Mfxl89wLhpbtbDXprjLs  Mfxl89wLhpbtbDXprjLs   \n",
       "6  qgACHvxcUdxV1FGHDVRD  qgACHvxcUdxV1FGHDVRD   \n",
       "\n",
       "                                            question response correct_answer  \\\n",
       "0         What is the strategy of a dummy regressor?        A              D   \n",
       "1  What is the purpose of training and testing on...        A              B   \n",
       "2  What is the difference between ridge regressio...        D              B   \n",
       "3  What is the difference between K nearest neigh...        B              C   \n",
       "4  What does a beta larger than one in the F-scor...        D              B   \n",
       "5  Does Mean Squared Error distinguish between ov...        A              B   \n",
       "6  What does the string 'precision_micro' represe...        C              A   \n",
       "\n",
       "  student_id           timestamp  \\\n",
       "0      ABCDE 2023-09-08 08:44:20   \n",
       "1      ABCDE 2023-09-09 09:42:54   \n",
       "2      ABCDE 2023-09-21 15:40:28   \n",
       "3      ABCDE 2023-10-12 21:20:39   \n",
       "4      ABCDE 2023-09-11 15:38:33   \n",
       "5      ABCDE 2023-10-05 06:16:45   \n",
       "6      ABCDE 2023-09-04 01:08:41   \n",
       "\n",
       "                                      topics_covered  \n",
       "0  [regression, supervised learning, linear regre...  \n",
       "1  [supervised learning, overfitting, feature eng...  \n",
       "2  [linear regression, regression, supervised lea...  \n",
       "3  [k-nn, linear regression, supervised learning,...  \n",
       "4  [supervised learning, classification, bias var...  \n",
       "5  [regression, linear regression, supervised lea...  \n",
       "6  [supervised learning, classification, feature ...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db[\"questions\"]\n",
    "documents = collection.find()\n",
    "# for doc in documents:\n",
    "#     print(doc)\n",
    "doc_count = collection.count_documents({})    \n",
    "print(doc_count)\n",
    "\n",
    "df = pd.DataFrame(list(documents))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['student_id'] = 'ABCDE'\n",
    "# # df['topics_covered'] = 'Supervised learning'\n",
    "# # df['topics_covered'] = df['topics_covered'].apply(lambda x: [x])\n",
    "# def random_abcd():\n",
    "#     return random.choice(['A', 'B', 'C', 'D'])\n",
    "\n",
    "# df['response'] = df.apply(lambda x: random_abcd(), axis=1)\n",
    "# df['correct_answer'] = df.apply(lambda x: random_abcd(), axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.studenthist.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f890d3b4d00>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtab = db['studenthist']\n",
    "records = df.to_dict('records')\n",
    "newtab.insert_many(records)\n",
    "# documents = newtab.find()\n",
    "# for doc in documents:\n",
    "#     print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_dash_api(progress):\n",
    "    \n",
    "#     url = 'https://comphcithree.eecs.umich.edu:8100/dash/siads542'\n",
    "#     headers = {'Content-type': 'application/json'}\n",
    "#     resp = requests.post(url, json=progress, headers=headers)\n",
    "#     return resp.json()\n",
    "\n",
    "# def explode_list(df, column_to_explode, fill_values):\n",
    "#         df = df.reset_index(drop=True)\n",
    "#         s = df[column_to_explode]\n",
    "#         i = np.arange(len(s)).repeat(s.str.len())\n",
    "#         return df.iloc[i].assign(**{column_to_explode: np.concatenate(s)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENARIO 1: no student history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ids = [''.join(choice(ascii_uppercase) for _ in range(5)) for _ in range(10)]\n",
    "topics = subset_df['Topics'].explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_students_1():    \n",
    "\n",
    "    start_date = pd.to_datetime('2023-08-29')\n",
    "    end_date = pd.to_datetime('2023-10-10')\n",
    "\n",
    "    feedback = []\n",
    "\n",
    "    # Loop through each student\n",
    "    for student_id in student_ids:\n",
    "      # Loop through each question for current student\n",
    "      for question_choice in quest_df['Question ID']:\n",
    "\n",
    "          question_info = quest_df.loc[quest_df['Question ID'] == question_choice]\n",
    "\n",
    "          question, correct_answer, topic = question_info['Question'].values[0], question_info['Correct'].values[0], question_info['Topics'].values[0]\n",
    "\n",
    "          all_answers = list(\"ABCD\")\n",
    "\n",
    "          if correct_answer in all_answers:\n",
    "              all_answers.remove(correct_answer)\n",
    "\n",
    "          if np.random.rand() < 0.5:\n",
    "              response = correct_answer\n",
    "          else: \n",
    "              response = np.random.choice(all_answers)\n",
    "\n",
    "          # randomly generate a date between the start and end dates\n",
    "          timestamp =  start_date + pd.Timedelta(days = int(np.random.randint(0, (end_date - start_date).days+1))) \n",
    "\n",
    "          feedback.append((question_choice, \n",
    "                           student_id, \n",
    "                           timestamp, # use the randomly generated timestamp here\n",
    "                           question,\n",
    "                           response,\n",
    "                           correct_answer,\n",
    "                           topic))\n",
    "\n",
    "    df_feedback = pd.DataFrame(feedback, columns=['question_id', \n",
    "                                                 'student_id', \n",
    "                                                 'timestamp', \n",
    "                                                 'question', \n",
    "                                                 'response',\n",
    "                                                 'correct_answer',\n",
    "                                                 'topics_covered'])\n",
    "    \n",
    "    df_feedback['correct/incorrect'] = (df_feedback['response'] == df_feedback['correct_answer']).astype(int)\n",
    "    print(df_feedback.student_id.unique())\n",
    "    \n",
    "    for i in df_feedback['student_id'].unique():\n",
    "        df = df_feedback[df_feedback['student_id']==i]\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "\n",
    "        df_new = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "\n",
    "        df_new = explode_list(df_new, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "        df_new.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "        df_new.reset_index(drop=True, inplace=True)\n",
    "        df_new['concept'] = df_new['concept'].str.lower()\n",
    "\n",
    "        concept2id = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        id2concept = {v: k for k, v in concept2id.items()}\n",
    "\n",
    "        df_new['concept'] = df_new['concept'].replace(id2concept)\n",
    "        df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "        df_new['concept'] = df_new['concept'].astype(int)\n",
    "\n",
    "        output_dict = df_new.apply(tuple, axis=1).tolist()\n",
    "\n",
    "        student_hist = {'progress': output_dict}\n",
    "\n",
    "        output = test_dash_api(student_hist)\n",
    "        output = dict(sorted(output.items(), key=lambda item: item[0]))\n",
    "        output['concept'] = sorted(output['concept'], key=lambda x: x[0])\n",
    "\n",
    "        filtered_courses = {}\n",
    "    #     filtered_courses['concept'] = output['concept'][:25]\n",
    "\n",
    "        freq_dict = {int(pair[1]): pair[0] for pair in output['concept']}\n",
    "\n",
    "        id_to_name = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        frequencies = {id_to_name[str(k)]: v for k,v in freq_dict.items()}\n",
    "        \n",
    "        print(\"\\n\" + i + \"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_students_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENARIO 2: students who have already have 1 topic strong from week 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ids = [''.join(choice(ascii_uppercase) for _ in range(5)) for _ in range(10)]\n",
    "topics = subset_df['Topics'].explode().unique().tolist() # Assumed 'Topics' as your column name\n",
    "st_strengths = {st_id: np.random.choice(topics, size=1, replace=False).tolist() for st_id in student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_students_2():    \n",
    "\n",
    "    start_date = pd.to_datetime('2023-08-29')\n",
    "    end_date = pd.to_datetime('2023-10-10')\n",
    "\n",
    "\n",
    "    feedback = []\n",
    "\n",
    "    # Loop through each student\n",
    "    for student_id in student_ids:\n",
    "      # Loop through each question for current student\n",
    "      for question_choice in quest_df['Question ID']:\n",
    "\n",
    "        question_info = quest_df.loc[quest_df['Question ID'] == question_choice]\n",
    "\n",
    "        question, correct_answer, question_topics = question_info['Question'].values[0], question_info['Correct'].values[0], question_info['Topics'].values[0]\n",
    "\n",
    "        all_answers = list(\"ABCD\")\n",
    "\n",
    "        if correct_answer in all_answers:\n",
    "            all_answers.remove(correct_answer)\n",
    "\n",
    "        # Check if question covers one of the topics the student is strong at\n",
    "        if any(topic in question_topics for topic in st_strengths[student_id]):\n",
    "            response = correct_answer\n",
    "        else:\n",
    "            response = np.random.choice(all_answers) # Student answers incorrectly in their weak topics\n",
    "\n",
    "        # randomly generate a date between the start and end dates\n",
    "        timestamp =  start_date + pd.Timedelta(days = int(np.random.randint(0, (end_date - start_date).days+1)))\n",
    "\n",
    "        feedback.append((question_choice, \n",
    "                         student_id, \n",
    "                         timestamp,\n",
    "                         question,\n",
    "                         response,\n",
    "                         correct_answer,\n",
    "                         question_topics))\n",
    "\n",
    "    df_feedback = pd.DataFrame(feedback, columns=['question_id', \n",
    "                                                  'student_id', \n",
    "                                                  'timestamp', \n",
    "                                                  'question', \n",
    "                                                  'response',\n",
    "                                                  'correct_answer',\n",
    "                                                  'topics_covered'])\n",
    "    \n",
    "    df_feedback['correct/incorrect'] = (df_feedback['response'] == df_feedback['correct_answer']).astype(int)\n",
    "    print(df_feedback.student_id.unique())\n",
    "    \n",
    "    for i in df_feedback['student_id'].unique():\n",
    "        df = df_feedback[df_feedback['student_id']==i]\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "\n",
    "        df_new = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "\n",
    "        df_new = explode_list(df_new, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "        df_new.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "        df_new.reset_index(drop=True, inplace=True)\n",
    "        df_new['concept'] = df_new['concept'].str.lower()\n",
    "\n",
    "        concept2id = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        id2concept = {v: k for k, v in concept2id.items()}\n",
    "\n",
    "        df_new['concept'] = df_new['concept'].replace(id2concept)\n",
    "        df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "        df_new['concept'] = df_new['concept'].astype(int)\n",
    "\n",
    "        output_dict = df_new.apply(tuple, axis=1).tolist()\n",
    "\n",
    "        student_hist = {'progress': output_dict}\n",
    "\n",
    "        output = test_dash_api(student_hist)\n",
    "        output = dict(sorted(output.items(), key=lambda item: item[0]))\n",
    "        output['concept'] = sorted(output['concept'], key=lambda x: x[0])\n",
    "\n",
    "        filtered_courses = {}\n",
    "    #     filtered_courses['concept'] = output['concept'][:25]\n",
    "\n",
    "        freq_dict = {int(pair[1]): pair[0] for pair in output['concept']}\n",
    "\n",
    "        id_to_name = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        frequencies = {id_to_name[str(k)]: v for k,v in freq_dict.items()}\n",
    "        \n",
    "        print(\"\\n\" + i + \"\\n\")\n",
    "        print(st_strengths[i])\n",
    "        print(\"\\n\")\n",
    "        print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_students_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENARIO 3: really advanced in topics from week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ids = [''.join(choice(ascii_uppercase) for _ in range(5)) for _ in range(10)]\n",
    "topics = subset_df['Topics'].explode().unique().tolist() # Assumed 'Topics' as your column name\n",
    "st_strengths = {st_id: np.random.choice(topics, size=5, replace=False).tolist() for st_id in student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ODbEgiET54WM",
    "outputId": "a833e8a8-36cb-404f-8bab-717b0f8b907a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def test_students_3():    \n",
    "\n",
    "    start_date = pd.to_datetime('2023-08-29')\n",
    "    end_date = pd.to_datetime('2023-10-10')\n",
    "\n",
    "\n",
    "    feedback = []\n",
    "\n",
    "    # Loop through each student\n",
    "    for student_id in student_ids:\n",
    "      # Loop through each question for current student\n",
    "      for question_choice in quest_df['Question ID']:\n",
    "\n",
    "        question_info = quest_df.loc[quest_df['Question ID'] == question_choice]\n",
    "\n",
    "        question, correct_answer, question_topics = question_info['Question'].values[0], question_info['Correct'].values[0], question_info['Topics'].values[0]\n",
    "\n",
    "        all_answers = list(\"ABCD\")\n",
    "\n",
    "        if correct_answer in all_answers:\n",
    "            all_answers.remove(correct_answer)\n",
    "\n",
    "        # Check if question covers one of the topics the student is strong at\n",
    "        if any(topic in question_topics for topic in st_strengths[student_id]):\n",
    "            response = correct_answer\n",
    "        else:\n",
    "            response = np.random.choice(all_answers) # Student answers incorrectly in their weak topics\n",
    "\n",
    "        # randomly generate a date between the start and end dates\n",
    "        timestamp =  start_date + pd.Timedelta(days = int(np.random.randint(0, (end_date - start_date).days+1)))\n",
    "\n",
    "        feedback.append((question_choice, \n",
    "                         student_id, \n",
    "                         timestamp,\n",
    "                         question,\n",
    "                         response,\n",
    "                         correct_answer,\n",
    "                         question_topics))\n",
    "\n",
    "    df_feedback = pd.DataFrame(feedback, columns=['question_id', \n",
    "                                                  'student_id', \n",
    "                                                  'timestamp', \n",
    "                                                  'question', \n",
    "                                                  'response',\n",
    "                                                  'correct_answer',\n",
    "                                                  'topics_covered'])\n",
    "    \n",
    "    df_feedback['correct/incorrect'] = (df_feedback['response'] == df_feedback['correct_answer']).astype(int)\n",
    "    print(df_feedback.student_id.unique())\n",
    "    \n",
    "    for i in df_feedback['student_id'].unique():\n",
    "        df = df_feedback[df_feedback['student_id']==i]\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "\n",
    "        df_new = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "\n",
    "        df_new = explode_list(df_new, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "        df_new.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "        df_new.reset_index(drop=True, inplace=True)\n",
    "        df_new['concept'] = df_new['concept'].str.lower()\n",
    "\n",
    "        concept2id = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        id2concept = {v: k for k, v in concept2id.items()}\n",
    "\n",
    "        df_new['concept'] = df_new['concept'].replace(id2concept)\n",
    "        df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "        df_new['concept'] = df_new['concept'].astype(int)\n",
    "\n",
    "        output_dict = df_new.apply(tuple, axis=1).tolist()\n",
    "\n",
    "        student_hist = {'progress': output_dict}\n",
    "\n",
    "        output = test_dash_api(student_hist)\n",
    "        output = dict(sorted(output.items(), key=lambda item: item[0]))\n",
    "        output['concept'] = sorted(output['concept'], key=lambda x: x[0])\n",
    "\n",
    "        filtered_courses = {}\n",
    "    #     filtered_courses['concept'] = output['concept'][:25]\n",
    "\n",
    "        freq_dict = {int(pair[1]): pair[0] for pair in output['concept']}\n",
    "\n",
    "        id_to_name = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "        frequencies = {id_to_name[str(k)]: v for k,v in freq_dict.items()}\n",
    "        \n",
    "        print(\"\\n\" + i + \"\\n\")\n",
    "        print(st_strengths[i])\n",
    "        print(\"\\n\")\n",
    "        print(frequencies)\n",
    "#         for j in st_strengths[i]:\n",
    "#             print(frequencies[j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_students_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ids = [''.join(choice(ascii_uppercase) for _ in range(5)) for _ in range(10)]\n",
    "topics = quest_df['Topics'].explode().unique().tolist() \n",
    "st_strengths = {st_id: np.random.choice(topics, size=5, replace=False).tolist() for st_id in student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2023-08-29')\n",
    "end_date = pd.to_datetime('2023-10-10')\n",
    "\n",
    "\n",
    "feedback = []\n",
    "\n",
    "# Loop through each student\n",
    "for student_id in student_ids:\n",
    "  # Loop through each question for current student\n",
    "  for question_choice in quest_df['Question ID']:\n",
    "\n",
    "    question_info = quest_df.loc[quest_df['Question ID'] == question_choice]\n",
    "\n",
    "    question, correct_answer, question_topics = question_info['Question'].values[0], question_info['Correct'].values[0], question_info['Topics'].values[0]\n",
    "\n",
    "    all_answers = list(\"ABCD\")\n",
    "\n",
    "    if correct_answer in all_answers:\n",
    "        all_answers.remove(correct_answer)\n",
    "\n",
    "    if any(topic in question_topics for topic in st_strengths[student_id]):\n",
    "        response = correct_answer\n",
    "    else:\n",
    "        response = np.random.choice(all_answers) # Student answers incorrectly in their weak topics\n",
    "\n",
    "    timestamp =  start_date + pd.Timedelta(days = int(np.random.randint(0, (end_date - start_date).days+1)))\n",
    "\n",
    "    feedback.append((question_choice, \n",
    "                     student_id, \n",
    "                     timestamp,\n",
    "                     question,\n",
    "                     response,\n",
    "                     correct_answer,\n",
    "                     question_topics))\n",
    "\n",
    "df_feedback = pd.DataFrame(feedback, columns=['question_id', \n",
    "                                              'student_id', \n",
    "                                              'timestamp', \n",
    "                                              'question', \n",
    "                                              'response',\n",
    "                                              'correct_answer',\n",
    "                                              'topics_covered'])\n",
    "\n",
    "df_feedback['correct/incorrect'] = (df_feedback['response'] == df_feedback['correct_answer']).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADCVO', 'JJERJ', 'HJAQN', 'HUVBL', 'HVDIJ', 'EEILT', 'ZXTPC',\n",
       "       'WKTGS', 'WIRAX', 'SSCRZ'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feedback.student_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADCVO': ['binary classifier',\n",
       "  'training data',\n",
       "  'refinement',\n",
       "  'linear regression',\n",
       "  'regularization'],\n",
       " 'JJERJ': ['feature extraction',\n",
       "  'feature representation',\n",
       "  'machine learning task',\n",
       "  'precision-recall curve',\n",
       "  'support vector'],\n",
       " 'HJAQN': ['false negative predictions',\n",
       "  'iterative process',\n",
       "  'user community',\n",
       "  'dummy regressors',\n",
       "  'data manipulation'],\n",
       " 'HUVBL': ['evaluation',\n",
       "  'batch learning',\n",
       "  'false negative predictions',\n",
       "  'activation functions',\n",
       "  'activepython'],\n",
       " 'HVDIJ': ['multi-agent',\n",
       "  'objective function',\n",
       "  'imbalanced classes',\n",
       "  'clustering',\n",
       "  'feature pre-processing'],\n",
       " 'EEILT': ['predict',\n",
       "  'generalization',\n",
       "  'kernel machines',\n",
       "  'clustering',\n",
       "  'stratified k-fold cross validation'],\n",
       " 'ZXTPC': ['online documentation',\n",
       "  'activation functions',\n",
       "  'user community',\n",
       "  'statistical distributions',\n",
       "  'active learning'],\n",
       " 'WKTGS': ['density estimation',\n",
       "  'deep learning',\n",
       "  'false positives',\n",
       "  'multi-agent',\n",
       "  'confusion matrix'],\n",
       " 'WIRAX': ['model selection',\n",
       "  'f-score',\n",
       "  'test data',\n",
       "  'customer facing prediction problems',\n",
       "  'optimization of functions'],\n",
       " 'SSCRZ': ['clustering',\n",
       "  'training and testing',\n",
       "  'multilayer perceptron',\n",
       "  'feature space',\n",
       "  'threshold']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dash_params.pk', 'rb') as file:\n",
    "    dash = pickle.load(file)\n",
    "    \n",
    "with open('SIADS_542_dep.pk', 'rb') as file:\n",
    "    concept_file = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_list(df, column_to_explode, fill_values):\n",
    "    df = df.reset_index(drop=True)\n",
    "    s = df[column_to_explode]\n",
    "    i = np.arange(len(s)).repeat(s.str.len())\n",
    "    return df.iloc[i].assign(**{column_to_explode: np.concatenate(s)})\n",
    "\n",
    "\n",
    "def get_dash_memory(dash_params,concepts, progress):\n",
    "    scheduler = DashScheduler(concepts, dash_params)\n",
    "    return scheduler.get_memory(progress)    \n",
    "\n",
    "def get_freq(df, student_uniqname, concept_dict):\n",
    "    rec_prob={}\n",
    "    id2concept = {k: c for k, c in enumerate(concept_file.nodes())}\n",
    "    id2concept = {k: v.strip() for k, v in id2concept.items()}\n",
    "    concept2id = {v.strip(): k for k, v in id2concept.items()}\n",
    "    df = df[df['student_id']==student_uniqname]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "    df['correct/incorrect'] = (df['response'] == df['correct_answer']).astype(int)\n",
    "    df = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "    \n",
    "    df_formatted = explode_list(df, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "    df_formatted.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "    df_formatted.reset_index(drop=True, inplace=True)\n",
    "    df_formatted['concept'] = df_formatted['concept'].map(concept2id)\n",
    "    df_formatted = df_formatted[df_formatted['concept'].apply(lambda x: str(x).isdigit())]\n",
    "    df_formatted['concept'] = df_formatted['concept'].astype(int)\n",
    "    tuple_list = [tuple(x) for x in df_formatted.values]\n",
    "    student_hist = {'progress': tuple_list}\n",
    "    \n",
    "    output = get_dash_memory(dash, concept_file, student_hist['progress'])\n",
    "    for i in output:\n",
    "        k = int(i[1])\n",
    "        v = float(i[0])\n",
    "        rec_prob[k] = v\n",
    "    recall_prob_dict = {id2concept.get(k, k): v for k, v in rec_prob.items()}\n",
    "    recall_prob_dict = {k.strip(): v for k, v in recall_prob_dict.items()}\n",
    "    recall_prob_dict = dict(sorted(recall_prob_dict.items(), key=lambda item: item[1]))\n",
    "    first_25_dict = dict(itertools.islice(recall_prob_dict.items(), 25))\n",
    "    frequencies = {k: round(1/(v**0.5)) for k,v in recall_prob_dict.items()}\n",
    "\n",
    "    return frequencies\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'classification',\n",
       " 1: 'k-nn',\n",
       " 2: 'online learning',\n",
       " 3: 'pca',\n",
       " 4: 'structured prediction',\n",
       " 5: 'feature engineering',\n",
       " 6: 'data cleaning',\n",
       " 7: 'data cleaning',\n",
       " 8: 'bias variance tradeoff',\n",
       " 9: 'active learning',\n",
       " 10: 'machine learning',\n",
       " 11: 'automl',\n",
       " 12: 'supervised learning',\n",
       " 13: 'feature learning',\n",
       " 14: 'learning curve',\n",
       " 15: 'feature engineering',\n",
       " 16: 'decision trees',\n",
       " 17: 'artificial neural networks',\n",
       " 18: 'batch learning',\n",
       " 19: 'supervised learning',\n",
       " 20: 'decision threshold',\n",
       " 21: 'logistic regression',\n",
       " 22: 'threshold',\n",
       " 23: 'statistical learning',\n",
       " 24: 'empirical risk minimization',\n",
       " 25: 'classification',\n",
       " 26: 'evaluation metrics',\n",
       " 27: 'precision and recall',\n",
       " 28: 'logistic regression',\n",
       " 29: 'support vector machine (svm)',\n",
       " 30: 'f-score',\n",
       " 31: 'customer facing prediction problems',\n",
       " 32: 'precision',\n",
       " 33: 'false positives',\n",
       " 34: 'machine learning evaluation',\n",
       " 35: 'computational learning theory',\n",
       " 36: 'evaluation metric',\n",
       " 37: 'user experience',\n",
       " 38: 'precision',\n",
       " 39: 'specificity',\n",
       " 40: 'false positive rate',\n",
       " 41: 'machine learning prediction',\n",
       " 42: 'predict',\n",
       " 43: 'stratified k-fold cross validation',\n",
       " 44: 'regression',\n",
       " 45: 'generalization',\n",
       " 46: 'cross validation',\n",
       " 47: 'fit',\n",
       " 48: 'model tuning',\n",
       " 49: 'leave one out cross validation',\n",
       " 50: 'score',\n",
       " 51: 'validation curve',\n",
       " 52: 'stratified k fold',\n",
       " 53: 'evaluation score',\n",
       " 54: 'test set',\n",
       " 55: 'learning curve',\n",
       " 56: 'machine learning algorithms',\n",
       " 57: 'parameter sweep',\n",
       " 58: 'train test split',\n",
       " 59: 'parameter tuning',\n",
       " 60: 'scikit-learn',\n",
       " 61: 'grid search',\n",
       " 62: 'ensembles bagging boosting random forest',\n",
       " 63: 'model evaluation',\n",
       " 64: 'semi-supervised learning',\n",
       " 65: 'unsupervised learning',\n",
       " 66: 'anomaly detection',\n",
       " 67: 'overfitting',\n",
       " 68: 'pre-pruning',\n",
       " 69: 'decision trees',\n",
       " 70: 'feature importance',\n",
       " 71: 'underfitting',\n",
       " 72: 'post-pruning',\n",
       " 73: 'image recognition',\n",
       " 74: 'cognitive computing',\n",
       " 75: 'gpu',\n",
       " 76: 'feature extraction',\n",
       " 77: 'convolutional neural network',\n",
       " 78: 'deep learning',\n",
       " 79: 'multilayer perceptron',\n",
       " 80: 'python',\n",
       " 81: 'software packages',\n",
       " 82: 'deep learning',\n",
       " 83: 'visualizing the data',\n",
       " 84: 't-sne',\n",
       " 85: 'dimension reduction',\n",
       " 86: 'visualization',\n",
       " 87: 'clustering',\n",
       " 88: 'clustering',\n",
       " 89: 'linear regression',\n",
       " 90: 'reinforcement learning',\n",
       " 91: 'self-supervised learning',\n",
       " 92: 'learning rate',\n",
       " 93: 'model complexity',\n",
       " 94: 'feature scaling',\n",
       " 95: 'ensembles bagging boosting random forest',\n",
       " 96: 'overfitting',\n",
       " 97: 'gradient boosted decision trees',\n",
       " 98: 'k-nn',\n",
       " 99: 'feature representation',\n",
       " 100: 'training and test sets',\n",
       " 101: 'training data',\n",
       " 102: 'model fitting',\n",
       " 103: 'evaluation methods',\n",
       " 104: 'parameter estimation',\n",
       " 105: 'instance based or memory based supervised learning',\n",
       " 106: 'instance based learning',\n",
       " 107: 'regression',\n",
       " 108: 'feature space',\n",
       " 109: 'training and test scores',\n",
       " 110: 'decision boundaries',\n",
       " 111: 'test data',\n",
       " 112: 'kernel machines',\n",
       " 113: 'linear classifier',\n",
       " 114: 'maximum margin',\n",
       " 115: 'original input space',\n",
       " 116: 'decision boundary',\n",
       " 117: 'feature transformation',\n",
       " 118: 'nonlinear decision boundary',\n",
       " 119: 'transformed feature space',\n",
       " 120: 'radial basis function',\n",
       " 121: 'support vector machine (svm)',\n",
       " 122: 'machine learning application',\n",
       " 123: 'iterative process',\n",
       " 124: 'machine learning task',\n",
       " 125: 'outlier detection',\n",
       " 126: 'machine learning algorithm',\n",
       " 127: 'accuracy score',\n",
       " 128: 'local outlier factor',\n",
       " 129: 'isolation forest',\n",
       " 130: 'unsupervised learning',\n",
       " 131: 'learning models',\n",
       " 132: 'optimal classifier',\n",
       " 133: 'crowdsourcing',\n",
       " 134: 'learning to rank',\n",
       " 135: 'evaluation method',\n",
       " 136: 'data representation',\n",
       " 137: 'accuracy',\n",
       " 138: 'active learning',\n",
       " 139: 'crowdsourcing',\n",
       " 140: 'human-in-the-loop',\n",
       " 141: 'failure analysis',\n",
       " 142: 'perceptron',\n",
       " 143: 'linear regression',\n",
       " 144: 'ridge regression',\n",
       " 145: 'computational learning theory',\n",
       " 146: 'regularization',\n",
       " 147: 'regularization',\n",
       " 148: 'polynomial regression',\n",
       " 149: 'lasso regression',\n",
       " 150: 'objective function',\n",
       " 151: 'development cycle',\n",
       " 152: 'ranking algorithm',\n",
       " 153: 'applied machine learning',\n",
       " 154: 'learning model refinement',\n",
       " 155: 'training',\n",
       " 156: 'evaluation',\n",
       " 157: 'parameter optimization',\n",
       " 158: 'optimization',\n",
       " 159: 'training phase',\n",
       " 160: 'application goal',\n",
       " 161: 'revenue prediction',\n",
       " 162: 'feature model refinement',\n",
       " 163: 'model selection',\n",
       " 164: 'evaluation',\n",
       " 165: 'relevance vector machine (rvm)',\n",
       " 166: 'refinement',\n",
       " 167: 'imbalanced classes',\n",
       " 168: 'healthcare applications',\n",
       " 169: 'learning to rank',\n",
       " 170: 'feature model',\n",
       " 171: 'surrogate metric',\n",
       " 172: 'dummy classifier',\n",
       " 173: 'dummy regressors',\n",
       " 174: 'performance characteristics',\n",
       " 175: 'optimization method',\n",
       " 176: 'user satisfaction',\n",
       " 177: 'refinement method',\n",
       " 178: 'performance metrics',\n",
       " 179: 'false negative predictions',\n",
       " 180: 'evaluation measures',\n",
       " 181: 'model performance',\n",
       " 182: 'gridsearchcv',\n",
       " 183: 'training and testing',\n",
       " 184: 'recall',\n",
       " 185: 'gridsearch',\n",
       " 186: 'kernel methods',\n",
       " 187: 'cross-validation',\n",
       " 188: 'cross-validation',\n",
       " 189: 'auc',\n",
       " 190: 'precision recall trade-off',\n",
       " 191: 'vc theory',\n",
       " 192: 'gridsearch',\n",
       " 193: 'binary classifiers',\n",
       " 194: 'multi-class classification',\n",
       " 195: 'binary classification',\n",
       " 196: 'binary',\n",
       " 197: 'multi-agent',\n",
       " 198: 'prediction',\n",
       " 199: 'categorical',\n",
       " 200: 'confusion matrix',\n",
       " 201: 'feature pre-processing',\n",
       " 202: 'text classification',\n",
       " 203: 'binary occurrence',\n",
       " 204: 'high dimensional dataset',\n",
       " 205: 'high dimensional datasets',\n",
       " 206: 'textual data',\n",
       " 207: 'correlation',\n",
       " 208: 'naive bayes',\n",
       " 209: 'activation function',\n",
       " 210: 'multilayer perceptron',\n",
       " 211: 'artificial neural networks',\n",
       " 212: 'activation functions',\n",
       " 213: 'nonlinear function',\n",
       " 214: 'bias variance tradeoff',\n",
       " 215: 'support vector',\n",
       " 216: 'binary classifier',\n",
       " 217: 'trade-off between precision and recall',\n",
       " 218: 'decision function',\n",
       " 219: 'roc curves',\n",
       " 220: 'precision-recall curve',\n",
       " 221: 'roc',\n",
       " 222: 'roc curve',\n",
       " 223: 'precision-recall curve',\n",
       " 224: 'precision and recall',\n",
       " 225: 'performance of a binary classifier',\n",
       " 226: 'python scripts',\n",
       " 227: 'statistical learning',\n",
       " 228: 'anaconda python distribution',\n",
       " 229: 'online documentation',\n",
       " 230: 'linear algebra',\n",
       " 231: 'python',\n",
       " 232: 'scipy',\n",
       " 233: 'matplotlib',\n",
       " 234: 'scikit-learn',\n",
       " 235: 'numpy',\n",
       " 236: 'python software foundation',\n",
       " 237: 'anaconda',\n",
       " 238: 'data analysis',\n",
       " 239: 'optimization of functions',\n",
       " 240: 'tutorials',\n",
       " 241: 'scientific computing',\n",
       " 242: 'sparse matrices',\n",
       " 243: 'user community',\n",
       " 244: 'python libraries',\n",
       " 245: 'winpython',\n",
       " 246: 'open source project',\n",
       " 247: 'activepython',\n",
       " 248: 'data analysis',\n",
       " 249: 'structured prediction',\n",
       " 250: 'code examples',\n",
       " 251: 'specialized mathematical functions',\n",
       " 252: 'statistical distributions',\n",
       " 253: 'sparse matrices',\n",
       " 254: 'machine learning libraries',\n",
       " 255: 'sample applications',\n",
       " 256: 'data visualization',\n",
       " 257: 'density estimation',\n",
       " 258: 'data manipulation',\n",
       " 259: 'web application servers',\n",
       " 260: 'python libraries',\n",
       " 261: 'pandas',\n",
       " 262: 'pip',\n",
       " 263: 'scipy',\n",
       " 264: 'random forest',\n",
       " 265: 'error analysis',\n",
       " 266: 'dummy classifiers',\n",
       " 267: 'mean shift',\n",
       " 268: 'precision recall curves',\n",
       " 269: 'scikit-learn datasets library',\n",
       " 270: 'synthetic datasets',\n",
       " 271: 'high dimensional',\n",
       " 272: 'high-dimensional data',\n",
       " 273: 'scatter plot'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2concept = {k: c for k, c in enumerate(concept_file.nodes())}\n",
    "id2concept = {k: v.strip() for k, v in id2concept.items()}\n",
    "id2concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'progress': [(5, 0, '08/08/2023'),\n",
       "  (16, 1, '08/09/2023'),\n",
       "  (5, 0, '08/10/2023'),\n",
       "  (9, 0, '08/11/2023'),\n",
       "  (4, 1, '08/12/2023'),\n",
       "  (0, 1, '08/13/2023'),\n",
       "  (10, 1, '08/14/2023'),\n",
       "  (11, 1, '08/15/2023'),\n",
       "  (19, 0, '08/16/2023'),\n",
       "  (10, 1, '08/17/2023'),\n",
       "  (18, 0, '08/18/2023'),\n",
       "  (3, 1, '08/19/2023'),\n",
       "  (1, 1, '08/20/2023'),\n",
       "  (5, 1, '08/21/2023'),\n",
       "  (5, 0, '08/22/2023'),\n",
       "  (0, 1, '08/23/2023'),\n",
       "  (17, 1, '08/24/2023'),\n",
       "  (5, 0, '08/25/2023'),\n",
       "  (2, 0, '08/26/2023'),\n",
       "  (16, 1, '08/27/2023'),\n",
       "  (1, 0, '08/28/2023'),\n",
       "  (12, 0, '08/29/2023'),\n",
       "  (20, 1, '08/30/2023'),\n",
       "  (7, 0, '08/31/2023'),\n",
       "  (14, 1, '09/01/2023'),\n",
       "  (20, 1, '09/02/2023'),\n",
       "  (8, 1, '09/03/2023'),\n",
       "  (8, 1, '09/04/2023'),\n",
       "  (4, 0, '09/05/2023'),\n",
       "  (7, 1, '09/06/2023')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'progress': [(5, 0, '08/08/2023'), (16, 1, '08/09/2023'), (5, 0, '08/10/2023'), (9, 0, '08/11/2023'), (4, 1, '08/12/2023'),\n",
    "                             (0, 1, '08/13/2023'), (10, 1, '08/14/2023'), (11, 1, '08/15/2023'), (19, 0, '08/16/2023'), (10, 1, '08/17/2023'),\n",
    "                             (18, 0, '08/18/2023'), (3, 1, '08/19/2023'), (1, 1, '08/20/2023'), (5, 1, '08/21/2023'), (5, 0, '08/22/2023'),\n",
    "                             (0, 1, '08/23/2023'), (17, 1, '08/24/2023'), (5, 0, '08/25/2023'), (2, 0, '08/26/2023'), (16, 1, '08/27/2023'),\n",
    "                             (1, 0, '08/28/2023'), (12, 0, '08/29/2023'), (20, 1, '08/30/2023'), (7, 0, '08/31/2023'), (14, 1, '09/01/2023'),\n",
    "                             (20, 1, '09/02/2023'), (8, 1, '09/03/2023'), (8, 1, '09/04/2023'), (4, 0, '09/05/2023'), (7, 1, '09/06/2023')]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification',\n",
       " 'k-nn',\n",
       " 'online learning',\n",
       " 'pca',\n",
       " 'structured prediction',\n",
       " 'feature engineering',\n",
       " 'data cleaning',\n",
       " 'data cleaning',\n",
       " 'bias variance tradeoff',\n",
       " 'active learning',\n",
       " 'machine learning',\n",
       " 'automl',\n",
       " 'supervised learning',\n",
       " 'feature learning',\n",
       " 'learning curve',\n",
       " 'feature engineering',\n",
       " 'decision trees',\n",
       " 'artificial neural networks',\n",
       " 'batch learning',\n",
       " 'supervised learning']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "first_20_values = list(islice(id2concept.values(), 20))\n",
    "first_20_values\n",
    "\n",
    "#code to get the default progress topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/zk_kkvns5w3fqc24ykgn4p5h0000gn/T/ipykernel_97341/2155190523.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
      "/var/folders/zj/zk_kkvns5w3fqc24ykgn4p5h0000gn/T/ipykernel_97341/2155190523.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['correct/incorrect'] = (df['response'] == df['correct_answer']).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature engineering': 7,\n",
       " 'bias variance tradeoff': 7,\n",
       " 'supervised learning': 7,\n",
       " 'ensembles bagging boosting random forest': 7,\n",
       " 'linear regression': 7,\n",
       " 'overfitting': 7,\n",
       " 'online learning': 7,\n",
       " 'batch learning': 7,\n",
       " 'active learning': 6,\n",
       " 'decision trees': 6,\n",
       " 'statistical learning': 6,\n",
       " 'data cleaning': 6,\n",
       " 'unsupervised learning': 6,\n",
       " 'naive bayes': 6,\n",
       " 'precision and recall': 6,\n",
       " 'k-nn': 6,\n",
       " 'evaluation metrics': 6,\n",
       " 'model selection': 6,\n",
       " 'scikit-learn': 6,\n",
       " 'logistic regression': 6,\n",
       " 'kernel machines': 6,\n",
       " 'classification': 6,\n",
       " 'learning curve': 6,\n",
       " 'regression': 6,\n",
       " 'support vector machine (svm)': 6,\n",
       " 'structured prediction': 6,\n",
       " 'model complexity': 6,\n",
       " 'anomaly detection': 6,\n",
       " 'decision threshold': 6,\n",
       " 'clustering': 6,\n",
       " 'pca': 6,\n",
       " 'cross validation': 6,\n",
       " 'semi-supervised learning': 6,\n",
       " 'human-in-the-loop': 6,\n",
       " 'regularization': 6,\n",
       " 'crowdsourcing': 6,\n",
       " 'empirical risk minimization': 5,\n",
       " 'cross-validation': 5,\n",
       " 'roc curve': 5,\n",
       " 'dimension reduction': 5,\n",
       " 'accuracy': 5,\n",
       " 'evaluation methods': 5,\n",
       " 'evaluation method': 5,\n",
       " 'evaluation': 5,\n",
       " 'parameter tuning': 5,\n",
       " 'training data': 5,\n",
       " 'instance based learning': 5,\n",
       " 'dummy classifier': 5,\n",
       " 'recall': 5,\n",
       " 'binary classification': 5,\n",
       " 'machine learning': 5,\n",
       " 'computational learning theory': 5,\n",
       " 'model tuning': 5,\n",
       " 'grid search': 5,\n",
       " 'machine learning algorithm': 5,\n",
       " 'learning to rank': 5,\n",
       " 'perceptron': 5,\n",
       " 'ridge regression': 5,\n",
       " 'imbalanced classes': 5,\n",
       " 'gridsearch': 5,\n",
       " 'scipy': 5,\n",
       " 'numpy': 5,\n",
       " 'feature learning': 5,\n",
       " 'underfitting': 5,\n",
       " 'reinforcement learning': 5,\n",
       " 'multi-class classification': 5,\n",
       " 'python': 5,\n",
       " 'model evaluation': 5,\n",
       " 'precision': 5,\n",
       " 'false positive rate': 5,\n",
       " 'generalization': 5,\n",
       " 'self-supervised learning': 5,\n",
       " 'test data': 5,\n",
       " 'feature transformation': 5,\n",
       " 'polynomial regression': 5,\n",
       " 'optimization': 5,\n",
       " 'precision-recall curve': 5,\n",
       " 'machine learning algorithms': 5,\n",
       " 'train test split': 5,\n",
       " 'iterative process': 5,\n",
       " 'optimal classifier': 5,\n",
       " 'auc': 5,\n",
       " 'high dimensional datasets': 5,\n",
       " 'anaconda python distribution': 5,\n",
       " 'linear algebra': 5,\n",
       " 'matplotlib': 5,\n",
       " 'data analysis': 5,\n",
       " 'optimization of functions': 5,\n",
       " 'sparse matrices': 5,\n",
       " 'python libraries': 5,\n",
       " 'statistical distributions': 5,\n",
       " 'data manipulation': 5,\n",
       " 'pandas': 5,\n",
       " 'pip': 5,\n",
       " 'error analysis': 5,\n",
       " 'artificial neural networks': 5,\n",
       " 'automl': 5,\n",
       " 'f-score': 5,\n",
       " 'visualization': 5,\n",
       " 'feature representation': 5,\n",
       " 'training and test sets': 5,\n",
       " 'model fitting': 5,\n",
       " 'radial basis function': 5,\n",
       " 'data representation': 5,\n",
       " 'failure analysis': 5,\n",
       " 'lasso regression': 5,\n",
       " 'objective function': 5,\n",
       " 'gridsearchcv': 5,\n",
       " 'kernel methods': 5,\n",
       " 'online documentation': 5,\n",
       " 'user community': 5,\n",
       " 'open source project': 5,\n",
       " 'specialized mathematical functions': 5,\n",
       " 'data visualization': 5,\n",
       " 'precision recall curves': 5,\n",
       " 'multilayer perceptron': 4,\n",
       " 'evaluation metric': 4,\n",
       " 'deep learning': 4,\n",
       " 'activation function': 4,\n",
       " 'threshold': 4,\n",
       " 'machine learning evaluation': 4,\n",
       " 'user experience': 4,\n",
       " 'specificity': 4,\n",
       " 'predict': 4,\n",
       " 'stratified k-fold cross validation': 4,\n",
       " 'fit': 4,\n",
       " 'leave one out cross validation': 4,\n",
       " 'score': 4,\n",
       " 'validation curve': 4,\n",
       " 'stratified k fold': 4,\n",
       " 'evaluation score': 4,\n",
       " 'test set': 4,\n",
       " 'parameter sweep': 4,\n",
       " 'pre-pruning': 4,\n",
       " 'feature importance': 4,\n",
       " 'post-pruning': 4,\n",
       " 'visualizing the data': 4,\n",
       " 't-sne': 4,\n",
       " 'learning rate': 4,\n",
       " 'feature scaling': 4,\n",
       " 'gradient boosted decision trees': 4,\n",
       " 'parameter estimation': 4,\n",
       " 'instance based or memory based supervised learning': 4,\n",
       " 'feature space': 4,\n",
       " 'training and test scores': 4,\n",
       " 'decision boundaries': 4,\n",
       " 'linear classifier': 4,\n",
       " 'maximum margin': 4,\n",
       " 'original input space': 4,\n",
       " 'decision boundary': 4,\n",
       " 'nonlinear decision boundary': 4,\n",
       " 'transformed feature space': 4,\n",
       " 'machine learning application': 4,\n",
       " 'machine learning task': 4,\n",
       " 'outlier detection': 4,\n",
       " 'accuracy score': 4,\n",
       " 'local outlier factor': 4,\n",
       " 'isolation forest': 4,\n",
       " 'learning models': 4,\n",
       " 'development cycle': 4,\n",
       " 'ranking algorithm': 4,\n",
       " 'applied machine learning': 4,\n",
       " 'learning model refinement': 4,\n",
       " 'training': 4,\n",
       " 'parameter optimization': 4,\n",
       " 'training phase': 4,\n",
       " 'application goal': 4,\n",
       " 'revenue prediction': 4,\n",
       " 'feature model refinement': 4,\n",
       " 'relevance vector machine (rvm)': 4,\n",
       " 'refinement': 4,\n",
       " 'healthcare applications': 4,\n",
       " 'feature model': 4,\n",
       " 'surrogate metric': 4,\n",
       " 'dummy regressors': 4,\n",
       " 'performance characteristics': 4,\n",
       " 'optimization method': 4,\n",
       " 'user satisfaction': 4,\n",
       " 'refinement method': 4,\n",
       " 'performance metrics': 4,\n",
       " 'false negative predictions': 4,\n",
       " 'evaluation measures': 4,\n",
       " 'model performance': 4,\n",
       " 'training and testing': 4,\n",
       " 'precision recall trade-off': 4,\n",
       " 'vc theory': 4,\n",
       " 'binary classifiers': 4,\n",
       " 'prediction': 4,\n",
       " 'text classification': 4,\n",
       " 'binary occurrence': 4,\n",
       " 'high dimensional dataset': 4,\n",
       " 'textual data': 4,\n",
       " 'correlation': 4,\n",
       " 'nonlinear function': 4,\n",
       " 'support vector': 4,\n",
       " 'binary classifier': 4,\n",
       " 'trade-off between precision and recall': 4,\n",
       " 'decision function': 4,\n",
       " 'roc curves': 4,\n",
       " 'roc': 4,\n",
       " 'performance of a binary classifier': 4,\n",
       " 'python scripts': 4,\n",
       " 'python software foundation': 4,\n",
       " 'anaconda': 4,\n",
       " 'tutorials': 4,\n",
       " 'scientific computing': 4,\n",
       " 'winpython': 4,\n",
       " 'activepython': 4,\n",
       " 'code examples': 4,\n",
       " 'machine learning libraries': 4,\n",
       " 'sample applications': 4,\n",
       " 'web application servers': 4,\n",
       " 'random forest': 4,\n",
       " 'dummy classifiers': 4,\n",
       " 'mean shift': 4,\n",
       " 'scikit-learn datasets library': 4,\n",
       " 'synthetic datasets': 4,\n",
       " 'high dimensional': 4,\n",
       " 'high-dimensional data': 4,\n",
       " 'scatter plot': 4,\n",
       " 'multi-agent': 4,\n",
       " 'binary': 4,\n",
       " 'categorical': 4,\n",
       " 'convolutional neural network': 4,\n",
       " 'false positives': 4,\n",
       " 'feature extraction': 4,\n",
       " 'confusion matrix': 4,\n",
       " 'machine learning prediction': 4,\n",
       " 'gpu': 4,\n",
       " 'customer facing prediction problems': 4,\n",
       " 'image recognition': 4,\n",
       " 'cognitive computing': 4,\n",
       " 'software packages': 4,\n",
       " 'feature pre-processing': 4,\n",
       " 'activation functions': 4,\n",
       " 'density estimation': 4}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = get_freq(df_feedback, 'WKTGS', concept_file)\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_selection(frequencies, quest_df):\n",
    "     # Start with all topic frequencies being the target ones\n",
    "    unsatisfied_freqs = {k: v for k, v in frequencies.items() if v != 0}\n",
    "    selected_questions = []\n",
    "\n",
    "    # Greedy selection of questions\n",
    "    while unsatisfied_freqs:\n",
    "\n",
    "        # Calculate the score of each question by conditionally filtering unselected questions, and only if they cover a topic with unsatisfied frequency remaining\n",
    "        question_scores = {q: sum(unsatisfied_freqs[topic] for topic in topics if topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0)\n",
    "                          for q, topics in quest_df[quest_df.Selected == False].set_index('Question').Topics.items() if any(topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0 for topic in topics)}\n",
    "\n",
    "        # If no question can satisfy the remaining unsatisfied frequencies, then break the loop\n",
    "        if not question_scores:\n",
    "            print(\"No more questions can satisfy the remaining topic frequencies.\")\n",
    "            break\n",
    "\n",
    "        # Select the question with the highest score\n",
    "        selected_q = max(question_scores, key=question_scores.get)\n",
    "        selected_questions.append(selected_q)\n",
    "\n",
    "        # Update the 'Selected' flag for the chosen question\n",
    "        quest_df.loc[quest_df.Question == selected_q, 'Selected'] = True\n",
    "\n",
    "        # Update the unsatisfied frequencies\n",
    "        for topic_list in quest_df.set_index('Question').loc[selected_q].Topics:  # Assume here each topic_list is a list\n",
    "            for topic in topic_list:  # Iterate over the items in each topic_list\n",
    "                if topic in unsatisfied_freqs:\n",
    "                    unsatisfied_freqs[topic] -= 1\n",
    "                    if unsatisfied_freqs[topic] == 0:\n",
    "                        unsatisfied_freqs.pop(topic)\n",
    "\n",
    "    selected_questions_df = pd.DataFrame(selected_questions, columns=['Question'])\n",
    "    final_df = selected_questions_df.merge(quest_df, on='Question', how='left')\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = question_selection(frequencies, quest_df)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = final['Question ID'].duplicated()\n",
    "final[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_feedback[df_feedback['student_id']=='WBEGU']\n",
    "\n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# df_new = df[['topics_covered', 'correct/incorrect', 'timestamp']]\n",
    "\n",
    "# df_new = explode_list(df_new, 'topics_covered', {'correct/incorrect': 'incorrect', 'timestamp': df['timestamp']})\n",
    "# df_new.columns = ['concept', 'correct/incorrect', 'timestamp']\n",
    "# df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df_new['concept'] = df_new['concept'].str.lower()\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2concept = {k: c for k, c in enumerate(concept_file.nodes())}\n",
    "# concept2id = {v.strip(): k for k, v in id2concept.items()}\n",
    "# id2concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new['concept'] = df_new['concept'].map(concept2id)\n",
    "# df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "# df_new['concept'] = df_new['concept'].astype(int)\n",
    "# tuple_list = [tuple(x) for x in df_new.values]\n",
    "# student_hist = {'progress': tuple_list}\n",
    "# student_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem = get_dash_memory(dash, concept_file, student_hist['progress'])\n",
    "# rec_prob = {}\n",
    "# for i in mem:\n",
    "#     k = int(i[1])\n",
    "#     v = float(i[0])\n",
    "#     rec_prob[k] = v\n",
    "    \n",
    "# rec_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall_prob_dict = {id2concept.get(k, k): v for k, v in rec_prob.items()}\n",
    "# recall_prob_dict = {k.strip(): v for k, v in recall_prob_dict.items()}\n",
    "# recall_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall_prob_dict = dict(sorted(recall_prob_dict.items(), key=lambda item: item[1]))\n",
    "# frequencies = {k: round(1/(v**0.5)) for k,v in recall_prob_dict.items()}\n",
    "# frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['topics_covered'] = df['topics_covered'].apply(ast.literal_eval)\n",
    "# df_new.reset_index(drop=True, inplace=True)\n",
    "# df_new['concept'] = df_new['concept'].str.lower()\n",
    "# df_new\n",
    "\n",
    "# concept2id = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "# id2concept = {v: k for k, v in concept2id.items()}\n",
    "\n",
    "# # df_new['concept'] = df_new['concept'].replace(id2concept)\n",
    "\n",
    "# df_new\n",
    "\n",
    "# # df_new[df_new['correct/incorrect']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.concept.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dash_memory(app, concepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new['concept'] = df_new['concept'].astype(int)\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output_dict = df_new.apply(tuple, axis=1).tolist()\n",
    "\n",
    "# student_hist = {'progress': output_dict}\n",
    "\n",
    "# print(student_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dash_params.pk', 'rb') as file:\n",
    "#     dash = pickle.load(file)\n",
    "    \n",
    "# with open('SIADS_542_dep.pk', 'rb') as file:\n",
    "#     concept_file = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_freq(uniqname, data, dash_params, concept_dict):\n",
    "#     rec_prob = {}\n",
    "#     id2concept = {k: c for k, c in enumerate(concept_file.nodes())}\n",
    "#     concept2id = {v.strip(): k for k, v in id2concept.items()}\n",
    "#     df_new = data[data['student_id']=='uniqname']\n",
    "#     df_new['concept'] = df_new['concept'].map(concept2id)\n",
    "#     df_new = df_new[df_new['concept'].apply(lambda x: str(x).isdigit())]\n",
    "#     df_new['concept'] = df_new['concept'].astype(int)\n",
    "#     tuple_list = [tuple(x) for x in df_new.values]\n",
    "#     student_hist = {'progress': tuple_list}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies = get_freq('WBEGU', df_feedback, dash, concept_file)\n",
    "# frequencies\n",
    "# # output = test_dash_api(student_hist)\n",
    "# # output = dict(sorted(output.items(), key=lambda item: item[0]))\n",
    "# # output['concept'] = sorted(output['concept'], key=lambda x: x[0])\n",
    "# # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_courses = {}\n",
    "# filtered_courses['concept'] = output['concept'][:25]\n",
    "# filtered_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_dict = {int(pair[1]): pair[0] for pair in filtered_courses['concept']}\n",
    "\n",
    "# id_to_name = concept_dict['siads542']['concept_tree']['concept2id']\n",
    "# frequencies = {id_to_name[str(k)]: round(1/(v**0.5)) for k,v in freq_dict.items()}\n",
    "# frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Start with all topic frequencies being the target ones\n",
    "# unsatisfied_freqs = {k: v for k, v in frequencies.items() if v != 0}\n",
    "# selected_questions = []\n",
    "\n",
    "# # Greedy selection of questions\n",
    "# while unsatisfied_freqs:\n",
    "\n",
    "#     # Calculate the score of each question by conditionally filtering unselected questions, and only if they cover a topic with unsatisfied frequency remaining\n",
    "#     question_scores = {q: sum(unsatisfied_freqs[topic] for topic in topics if topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0)\n",
    "#                       for q, topics in quest_df[quest_df.Selected == False].set_index('Question').Topics.items() if any(topic in unsatisfied_freqs and unsatisfied_freqs[topic] > 0 for topic in topics)}\n",
    "\n",
    "#     # If no question can satisfy the remaining unsatisfied frequencies, then break the loop\n",
    "#     if not question_scores:\n",
    "#         print(\"No more questions can satisfy the remaining topic frequencies.\")\n",
    "#         break\n",
    "\n",
    "#     # Select the question with the highest score\n",
    "#     selected_q = max(question_scores, key=question_scores.get)\n",
    "#     selected_questions.append(selected_q)\n",
    "\n",
    "#     # Update the 'Selected' flag for the chosen question\n",
    "#     quest_df.loc[quest_df.Question == selected_q, 'Selected'] = True\n",
    "    \n",
    "#     # Update the unsatisfied frequencies\n",
    "#     for topic_list in quest_df.set_index('Question').loc[selected_q].Topics:  # Assume here each topic_list is a list\n",
    "#         for topic in topic_list:  # Iterate over the items in each topic_list\n",
    "#             if topic in unsatisfied_freqs:\n",
    "#                 unsatisfied_freqs[topic] -= 1\n",
    "#                 if unsatisfied_freqs[topic] == 0:\n",
    "#                     unsatisfied_freqs.pop(topic)\n",
    "\n",
    "\n",
    "# print(selected_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_questions_df = pd.DataFrame(selected_questions, columns=['Question'])\n",
    "# selected_questions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = selected_questions_df.merge(quest_df, on='Question', how='left')\n",
    "# final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
